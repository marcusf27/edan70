{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kalls\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\datapoints\\__init__.py:12: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n",
      "C:\\Users\\kalls\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torchvision\\transforms\\v2\\__init__.py:54: UserWarning: The torchvision.datapoints and torchvision.transforms.v2 namespaces are still Beta. While we do not expect major breaking changes, some APIs may still change according to user feedback. Please submit any feedback you may have in this issue: https://github.com/pytorch/vision/issues/6753, and you can also check out https://github.com/pytorch/vision/issues/7319 to learn more about the APIs that we suspect might involve future changes. You can silence this warning by calling torchvision.disable_beta_transforms_warning().\n",
      "  warnings.warn(_BETA_TRANSFORMS_WARNING)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\kalls\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import Trainer, TrainingArguments\n",
    "from transformers import AutoTokenizer\n",
    "from requests_html import AsyncHTMLSession, HTMLSession\n",
    "from bs4 import BeautifulSoup\n",
    "import asyncio\n",
    "import logging\n",
    "import json\n",
    "import re\n",
    "\n",
    "logging.disable(logging.WARNING)\n",
    "\n",
    "ed2_range = range(117910, 251508)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def debug_print(message, debug=True):\n",
    "    \n",
    "    if debug:\n",
    "        print(message)\n",
    "\n",
    "def convert_keys_to_int(json_dict):\n",
    "    \n",
    "    return { (int(key) if key.isdigit() else key): value for key, value in json_dict.items() }\n",
    "\n",
    "def filter_entries(entries, edition=None, articles=None):\n",
    "    \n",
    "    if edition:\n",
    "        entries = entries.get(edition, {})\n",
    "    \n",
    "        if articles:\n",
    "            entries = { article: item for article, item in entries.items() if article in articles}\n",
    "\n",
    "    return entries\n",
    "\n",
    "def load_json(path, edition=None, articles=None):\n",
    "    \n",
    "    try:\n",
    "        with open(path + '.json', 'r', encoding='utf-8') as file:\n",
    "            return filter_entries(json.load(file, object_hook=convert_keys_to_int), edition, articles)\n",
    "\n",
    "    except (FileNotFoundError, json.JSONDecodeError):\n",
    "        with open(path + '.json', 'w', encoding='utf-8') as file:\n",
    "            json.dump({ }, file, ensure_ascii=False, indent=4)\n",
    "        return { }\n",
    "\n",
    "def save_json(path, entries, edition=None, reset=False, sort_keys=False):\n",
    "    \n",
    "    temp_entries = entries   \n",
    "    entries = ({ edition: { } } if edition else { }) if reset else load_json(path)\n",
    "\n",
    "    entries.setdefault(edition, {})\n",
    "    \n",
    "    (entries[edition] if edition else entries).update(temp_entries)\n",
    "    \n",
    "    try:\n",
    "        with open(path + '.json', 'w', encoding='utf-8') as file:\n",
    "            json.dump(entries, file, ensure_ascii=False, indent=4, sort_keys=sort_keys)\n",
    "\n",
    "    except:\n",
    "        pass\n",
    "        \n",
    "def find_missing_articles(edition, articles, path):\n",
    "\n",
    "    return articles - load_json(path).get(edition, { }).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "async def fetch_article(\n",
    "    edition, article, session=AsyncHTMLSession(), semaphore=asyncio.Semaphore(), max_tries=3, debug=False):\n",
    "    \n",
    "    url = f'https://nordiskfamiljebok.dh.gu.se/article/{edition}/{(article if edition == 1 else article + ed2_range[0] - 1)}'\n",
    "    \n",
    "    async with semaphore:\n",
    "\n",
    "        debug_print(f\"Fetching {'1st' if article == 1 else f'{article}nd'} article from {'1st' if edition == 1 else f'{edition}nd'} edition\", debug)\n",
    "        \n",
    "        for n in range(1, max_tries + 1):\n",
    "            try:\n",
    "                response = await session.get(url)\n",
    "                await response.html.arender(timeout=5*n, sleep=n/10)\n",
    "                \n",
    "                soup = BeautifulSoup(response.html.html, \"html.parser\")\n",
    "                \n",
    "                entry = {\n",
    "                    'url': url,\n",
    "                    'title': soup.find('h1', {'data-v-5ad7308b': True}).decode_contents(),\n",
    "                    'text': soup.find('article', {'data-v-5ad7308b': True}).decode_contents()\n",
    "                }\n",
    "                debug_print(f\"Successfully fetched and rendered article {article}, {'1st' if edition == 1 else f'{edition}nd'} edition\", debug)\n",
    "                \n",
    "                return entry\n",
    "                \n",
    "            except:\n",
    "                debug_print(f\"Failed to fetch or render article {article}, {'1st' if edition == 1 else f'{edition}nd'} edition.\\nRetrying with larger timeout...\", debug)\n",
    "    \n",
    "    debug_print(f\"Failed to fetch article {article}, {'1st' if edition == 1 else f'{edition}nd'} edition\", debug)\n",
    "     \n",
    "    return None\n",
    "\n",
    "async def load_articles(\n",
    "    edition, articles, path='articles', force_fetch=False,\n",
    "    max_concurrent_tasks=5, max_tries=3, logging_step=20,\n",
    "    sort=True, get_all=True, debug=False):\n",
    "    \n",
    "    articles_to_fetch = articles if force_fetch else find_missing_articles(edition, articles, path)\n",
    "\n",
    "    debug_print(f'{len(articles)} articles to fetch: {articles}', debug)\n",
    "    \n",
    "    if logging_step > 0:\n",
    "        articles_to_fetch = list(articles_to_fetch)\n",
    "        articles_list = [articles_to_fetch[i:i + logging_step] for i in range(0, len(articles_to_fetch), logging_step)]\n",
    "  \n",
    "    else:\n",
    "        articles_list = [[articles]]\n",
    "\n",
    "    session = AsyncHTMLSession()\n",
    "    semaphore = asyncio.Semaphore(max_concurrent_tasks)\n",
    "    \n",
    "    entries = load_json(path)\n",
    "    entries.setdefault(edition, { })\n",
    "        \n",
    "    for i, article_list in enumerate(articles_list, 1):\n",
    "        debug_print(f'Step {i}/{len(articles_list)}\\nArticles: {article_list}\\n')\n",
    "        \n",
    "        async with asyncio.TaskGroup() as task_group:\n",
    "            tasks = [\n",
    "                task_group.create_task(\n",
    "                    fetch_article(edition, article, session, semaphore, max_tries, debug))\n",
    "                for article in article_list\n",
    "            ]\n",
    "        \n",
    "        for (task, article) in zip(tasks, article_list):\n",
    "            \n",
    "            try:\n",
    "                entry = task.result()\n",
    "                \n",
    "                if entry:\n",
    "                    entries[edition][article] = entry\n",
    "\n",
    "                else:\n",
    "                    entries[edition].pop(article, None)\n",
    "                                \n",
    "            except:\n",
    "                pass\n",
    "        \n",
    "        if sort:\n",
    "            entries = dict(sorted({ key: dict(sorted(value.items())) for key, value in entries.items() }.items()))\n",
    "\n",
    "        save_json(path, entries)\n",
    "        debug_print(f'Saving...\\n')\n",
    "\n",
    "    return entries if get_all else filter_entries(entries, edition, articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "articles_range = range(1, 20000)\n",
    "articles = await load_articles(2, articles_range, max_concurrent_tasks=3, logging_step=50, max_tries=3)\n",
    "articles = await load_articles(1, articles_range, max_concurrent_tasks=3, logging_step=50, max_tries=3) #ed2_range[0] + 1\n",
    "articles_range = range(1, 30000)\n",
    "articles = await load_articles(2, articles_range, max_concurrent_tasks=3, logging_step=50, max_tries=3)\n",
    "articles = await load_articles(1, articles_range, max_concurrent_tasks=3, logging_step=50, max_tries=3) #ed2_range[0] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import locale\n",
    "\n",
    "locale.setlocale(locale.LC_COLLATE, 'sv_SE.UTF-8')\n",
    "\n",
    "def segment_text(entries, edition, article):\n",
    "\n",
    "    entry = entries.get(edition, {}).get(article, {})\n",
    "\n",
    "    '''\n",
    "    segments = re.split(r\"\\s*(?:<br\\s*/?>)+\\s*\", text)\n",
    "\n",
    "    last_valid_segment = None\n",
    "    last_valid_word = None\n",
    "    valid_segments = {}\n",
    "\n",
    "    for segment in segments:\n",
    "        # segment = unicodedata.normalize('NFC', segment)\n",
    "        clean_segment = re.sub(r\"<.*?>\", '', segment).strip().lower()\n",
    "\n",
    "        try:\n",
    "            first_word = re.match(r\"\\b(\\w[\\w']*)\", clean_segment).group(0)  # Match the first word\n",
    "            first_word_uml = re.sub(r'ii', 'ü', first_word)\n",
    "        except:\n",
    "            first_word = first_word_uml = ''\n",
    "\n",
    "        if last_valid_segment:\n",
    "\n",
    "            if (last_valid_word < first_word or last_valid_word < first_word_uml\n",
    "                and (re.match(r\"[\\w'-]+[\\s]*[.,\\(\\[]\", clean_segment))):\n",
    "                valid_segments[last_valid_word] = last_valid_segment\n",
    "                last_valid_segment = clean_segment\n",
    "                last_valid_word = first_word\n",
    "                #print(\"NEW -\", \"HEAD:\", first_word, \"SEGMENT:\", clean_segment)\n",
    "\n",
    "            else:\n",
    "                last_valid_segment += '\\n' + clean_segment\n",
    "                #print(\"OLD -\", \"HEAD:\", first_word, \"SEGMENT:\", clean_segment)\n",
    "        else:\n",
    "            #print(\"NEW -\", \"HEAD:\", first_word, \"SEGMENT:\", clean_segment)\n",
    "            last_valid_segment = clean_segment\n",
    "            last_valid_word = first_word\n",
    "\n",
    "    valid_segments[last_valid_word] = last_valid_segment\n",
    "    \n",
    "    return valid_segments\n",
    "    '''\n",
    "    \n",
    "    return [{ 'head': entry['title'], 'text': entry['text']}]\n",
    "\n",
    "async def load_segments(\n",
    "    edition, articles, articles_path='articles', segments_path='segments',\n",
    "    force_fetch=False, max_concurrent_tasks=10, max_tries=3, logging_step=20,\n",
    "    sort=False, force_segmentation=False, get_all=True, debug=False):\n",
    "    \n",
    "    entries = load_json(segments_path)  \n",
    "    entries.setdefault(edition, { })\n",
    "    \n",
    "    articles_to_segment = articles if force_segmentation else find_missing_articles(edition, articles, segments_path)\n",
    "\n",
    "    article_entries = (await load_articles(\n",
    "        edition, articles_to_segment, articles_path, force_fetch,\n",
    "        max_concurrent_tasks, max_tries, logging_step, sort, True, debug))\n",
    " \n",
    "    for article in articles_to_segment:\n",
    "\n",
    "        entries[edition][article] = []\n",
    "        \n",
    "        for entry in segment_text(article_entries, edition, article):\n",
    "            head = entry['head']\n",
    "            text = entry['text']\n",
    "            \n",
    "            references = re.findall(r\". Se <span>(.*?)</span>\\.\", text)\n",
    "            \n",
    "            entry = {\n",
    "                'head': head,\n",
    "                'raw_text': text,\n",
    "                'text': re.sub(r\"<.*?>\", '', text).strip().lower(),\n",
    "                'label': None,\n",
    "                'qid': None,\n",
    "                'latitude': None,\n",
    "                'longitude': None,\n",
    "                'cross_refs': references\n",
    "            }\n",
    "            \n",
    "            entries[edition][article].append(entry)\n",
    "            \n",
    "    if sort:\n",
    "        entries = { key: dict(sorted(value.items())) for key, value in sorted(entries.items()) } \n",
    "\n",
    "    save_json(segments_path, entries)\n",
    "\n",
    "    return entries if get_all else filter_entries(entries, edition, articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs:\n",
      "\n",
      "1. Label as location\n",
      "2. Label as other\n",
      "3. Go back one step\n",
      "4. Save\n",
      "5. Exit\n",
      "\n",
      "1/200:\n",
      "Text: <b>Apprehension</b> (Lat. apprehénsio, af <i>apprehéndere</i>), <i>jur.,</i> den handling, hvarigenom en person tager en sak i besittning.\n",
      "Label: Undefined\n",
      "\n",
      "You chose 'Exit'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import keyboard\n",
    "import time\n",
    "\n",
    "idx2cat = {\n",
    "    0: 'Undefined',\n",
    "    1: 'Person',\n",
    "    2: 'Location',\n",
    "    3: 'Other'\n",
    "}\n",
    "\n",
    "#splits = {'train': 'train.json', 'validation': 'validation.json'}\n",
    "#df = pd.read_json(\"hf://datasets/pnugues/nf_1876/\" + splits[\"train\"])\n",
    "df = pd.read_csv('annotations.csv', index_col=0)\n",
    "\n",
    "i = 0\n",
    "last_i = -1\n",
    "\n",
    "filtered_df = df[df['label'] == 0].index\n",
    "\n",
    "exit = False\n",
    "\n",
    "actions = {\n",
    "    '1': 'Label as location',\n",
    "    '2': 'Label as other',\n",
    "    '3': 'Go back one step',\n",
    "    '4': 'Save',\n",
    "    '5': 'Exit'\n",
    "}\n",
    "\n",
    "\n",
    "print('Inputs:\\n')\n",
    "\n",
    "for key, action in actions.items():\n",
    "    print(f'{key}. {action}')\n",
    "\n",
    "print()\n",
    "\n",
    "while (True):\n",
    "    \n",
    "    item = df.loc[filtered_df[i]]\n",
    "    \n",
    "    text = item['text']\n",
    "    label = item['label']\n",
    "    \n",
    "    if last_i != i:\n",
    "        print(f'{i+1}/{len(filtered_df)}:\\nText: {text}\\nLabel: {idx2cat[label]}\\n')\n",
    "\n",
    "    last_i = i\n",
    "    \n",
    "    key_press = keyboard.read_key()\n",
    "\n",
    "    if key_press in actions.keys():\n",
    "        print(f'You chose \\'{actions[key_press]}\\'\\n')\n",
    "    \n",
    "    if key_press in { '1', '2'}:\n",
    "        df.loc[filtered_df[i], 'label'] = int(key_press) + 1\n",
    "        i = min(i + 1, len(df) - 1)\n",
    "        \n",
    "    if key_press == '3':\n",
    "        i = max(i - 1, 0)\n",
    "    5\n",
    "    if key_press == '4':\n",
    "        df.to_csv('annotations_edited.csv', index=False)\n",
    "        \n",
    "    if key_press == \"5\":\n",
    "        break\n",
    "    \n",
    "    time.sleep(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('KB/bert-base-swedish-cased')\n",
    "\n",
    "def tokenize(batch, idx = 'text'):\n",
    "    return tokenizer(batch[idx], padding='max_length', truncation=True, max_length=512, return_tensors='pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 320\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['label', 'text'],\n",
       "        num_rows: 80\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('annotations_edited.csv', index_col=0)\n",
    "\n",
    "segments = df[df['label'] != 0]\n",
    "\n",
    "segments.loc[:, 'label'] = segments['label'] - 1\n",
    "\n",
    "segments = Dataset.from_pandas(segments)\n",
    "segments = segments.train_test_split(test_size=0.2)\n",
    "segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0f796e61fee4104913f6a4818efe217",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/320 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c770f9dfb697480280b9e3c3f32b35c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/80 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "segments_encoded = segments.map(tokenize, batched=True, batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kalls\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\_utils.py:776: UserWarning: TypedStorage is deprecated. It will be removed in the future and UntypedStorage will be the only storage class. This should only matter to you if you are using storages directly.  To access UntypedStorage directly, use tensor.untyped_storage() instead of tensor.storage()\n",
      "  return self.fget.__get__(instance, owner)()\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "num_labels = 3\n",
    "\n",
    "model = (AutoModelForSequenceClassification\n",
    "         .from_pretrained('KB/bert-base-swedish-cased', num_labels=num_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    f1 = f1_score(labels, preds, average=\"weighted\")\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    return {\"accuracy\": acc, \"f1\": f1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kalls\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\training_args.py:1568: FutureWarning: `evaluation_strategy` is deprecated and will be removed in version 4.46 of 🤗 Transformers. Use `eval_strategy` instead\n",
      "  warnings.warn(\n",
      "C:\\Users\\kalls\\AppData\\Local\\Temp\\ipykernel_15500\\3330379601.py:18: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(model=model, args=training_args,\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a95ce47cf7f4fd9a00ccd10b335a3a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "834b1de0762f497391d4bf6b95f2abda",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_loss': 0.19465653598308563, 'eval_accuracy': 0.925, 'eval_f1': 0.9259216539479151, 'eval_runtime': 67.5328, 'eval_samples_per_second': 1.185, 'eval_steps_per_second': 0.074, 'epoch': 1.0}\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 23\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtransformers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Trainer\n\u001b[0;32m     18\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(model\u001b[38;5;241m=\u001b[39mmodel, args\u001b[38;5;241m=\u001b[39mtraining_args, \n\u001b[0;32m     19\u001b[0m                   compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[0;32m     20\u001b[0m                   train_dataset\u001b[38;5;241m=\u001b[39msegments_encoded[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     21\u001b[0m                   eval_dataset\u001b[38;5;241m=\u001b[39msegments_encoded[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[0;32m     22\u001b[0m                   tokenizer\u001b[38;5;241m=\u001b[39mtokenizer)\n\u001b[1;32m---> 23\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     24\u001b[0m trainer\u001b[38;5;241m.\u001b[39msave_model()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\trainer.py:2123\u001b[0m, in \u001b[0;36mTrainer.train\u001b[1;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[0;32m   2121\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[0;32m   2122\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 2123\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2124\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2125\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2126\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2127\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2128\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\trainer.py:2481\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[1;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[0;32m   2475\u001b[0m context \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   2476\u001b[0m     functools\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mno_sync, model\u001b[38;5;241m=\u001b[39mmodel)\n\u001b[0;32m   2477\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(batch_samples) \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   2478\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m contextlib\u001b[38;5;241m.\u001b[39mnullcontext\n\u001b[0;32m   2479\u001b[0m )\n\u001b[0;32m   2480\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m context():\n\u001b[1;32m-> 2481\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtraining_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2483\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   2484\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[0;32m   2485\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_xla_available()\n\u001b[0;32m   2486\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[0;32m   2487\u001b[0m ):\n\u001b[0;32m   2488\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[0;32m   2489\u001b[0m     tr_loss \u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m+\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\trainer.py:3579\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[1;34m(self, model, inputs, num_items_in_batch)\u001b[0m\n\u001b[0;32m   3576\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m   3578\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[1;32m-> 3579\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_items_in_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3581\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m inputs\n\u001b[0;32m   3582\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   3583\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   3584\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mtorch_empty_cache_steps \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m   3585\u001b[0m ):\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\trainer.py:3633\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[1;34m(self, model, inputs, return_outputs, num_items_in_batch)\u001b[0m\n\u001b[0;32m   3631\u001b[0m         loss_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnum_items_in_batch\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m num_items_in_batch\n\u001b[0;32m   3632\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mloss_kwargs}\n\u001b[1;32m-> 3633\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3634\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[0;32m   3635\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[0;32m   3636\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1668\u001b[0m, in \u001b[0;36mBertForSequenceClassification.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1660\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1661\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[0;32m   1662\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[0;32m   1663\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[0;32m   1664\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[0;32m   1665\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   1666\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m-> 1668\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbert\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1669\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1670\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtoken_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtoken_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1672\u001b[0m \u001b[43m    \u001b[49m\u001b[43mposition_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mposition_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1674\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1675\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1676\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1677\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1678\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1680\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   1682\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(pooled_output)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\models\\bert\\modeling_bert.py:1142\u001b[0m, in \u001b[0;36mBertModel.forward\u001b[1;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m   1135\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[0;32m   1136\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[0;32m   1137\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[0;32m   1138\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[0;32m   1139\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[0;32m   1140\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[1;32m-> 1142\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1143\u001b[0m \u001b[43m    \u001b[49m\u001b[43membedding_output\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1144\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mextended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1145\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1146\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1147\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_extended_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1148\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpast_key_values\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_key_values\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1149\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1150\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1151\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1152\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1153\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1154\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   1155\u001b[0m pooled_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler(sequence_output) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpooler \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\models\\bert\\modeling_bert.py:695\u001b[0m, in \u001b[0;36mBertEncoder.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[0;32m    684\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_gradient_checkpointing_func(\n\u001b[0;32m    685\u001b[0m         layer_module\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__call__\u001b[39m,\n\u001b[0;32m    686\u001b[0m         hidden_states,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    692\u001b[0m         output_attentions,\n\u001b[0;32m    693\u001b[0m     )\n\u001b[0;32m    694\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 695\u001b[0m     layer_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mlayer_module\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    696\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    697\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    698\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    699\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    700\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    701\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    702\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    703\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    705\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m layer_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    706\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_cache:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\models\\bert\\modeling_bert.py:585\u001b[0m, in \u001b[0;36mBertLayer.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    574\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    575\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    582\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[0;32m    583\u001b[0m     \u001b[38;5;66;03m# decoder uni-directional self-attention cached key/values tuple is at positions 1,2\u001b[39;00m\n\u001b[0;32m    584\u001b[0m     self_attn_past_key_value \u001b[38;5;241m=\u001b[39m past_key_value[:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m past_key_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m--> 585\u001b[0m     self_attention_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    587\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    588\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    589\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    590\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mself_attn_past_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    592\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m self_attention_outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m    594\u001b[0m     \u001b[38;5;66;03m# if decoder, the last output is tuple of self-attn cache\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\transformers\\models\\bert\\modeling_bert.py:515\u001b[0m, in \u001b[0;36mBertAttention.forward\u001b[1;34m(self, hidden_states, attention_mask, head_mask, encoder_hidden_states, encoder_attention_mask, past_key_value, output_attentions)\u001b[0m\n\u001b[0;32m    505\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[0;32m    506\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    507\u001b[0m     hidden_states: torch\u001b[38;5;241m.\u001b[39mTensor,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    513\u001b[0m     output_attentions: Optional[\u001b[38;5;28mbool\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m    514\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor]:\n\u001b[1;32m--> 515\u001b[0m     self_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mself\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    516\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    517\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    518\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    519\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    520\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    521\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_key_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    522\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    523\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    524\u001b[0m     attention_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moutput(self_outputs[\u001b[38;5;241m0\u001b[39m], hidden_states)\n\u001b[0;32m    525\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m (attention_output,) \u001b[38;5;241m+\u001b[39m self_outputs[\u001b[38;5;241m1\u001b[39m:]  \u001b[38;5;66;03m# add attentions if we output them\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\torch\\nn\\modules\\module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "batch_size = 16\n",
    "logging_steps = 1# len(segments_encoded) // batch_size\n",
    "model_name = f\"bert-finetuned-segments\"\n",
    "training_args = TrainingArguments(output_dir=model_name,\n",
    "                                  num_train_epochs=2,\n",
    "                                  learning_rate=2e-5,\n",
    "                                  per_device_train_batch_size=batch_size,\n",
    "                                  per_device_eval_batch_size=batch_size,\n",
    "                                  weight_decay=0.01,\n",
    "                                  evaluation_strategy=\"epoch\",\n",
    "                                  disable_tqdm=False,\n",
    "                                  log_level=\"error\")\n",
    "\n",
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(model=model, args=training_args, \n",
    "                  compute_metrics=compute_metrics,\n",
    "                  train_dataset=segments_encoded[\"train\"],\n",
    "                  eval_dataset=segments_encoded[\"test\"],\n",
    "                  tokenizer=tokenizer)\n",
    "trainer.train()\n",
    "#trainer.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kalls\\AppData\\Local\\Temp\\ipykernel_6088\\176640000.py:6: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(model=model, tokenizer=tokenizer)\n"
     ]
    }
   ],
   "source": [
    "model = (AutoModelForSequenceClassification\n",
    "         .from_pretrained(\"bert-finetuned-segments\"))\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"bert-finetuned-segments\")\n",
    "\n",
    "trainer = Trainer(model=model, tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "651f51c873834727bee9eb8fe5ffee05",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds_output = trainer.predict(segments_encoded[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjoAAAIjCAYAAAAKkbGTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABVcElEQVR4nO3dd1yV5f/H8fcBWTIFB7gAxYHb3Cu0LErLHC3TglyllaM0tVxkaUNNrdzfRM3Vt9Svo+FIrdRKy1WhuTVHKgaIAxnX7w9/njyCCQmCd6/n43Eedq77uu/7cx3u4H2u+77PsRljjAAAACzIKb8LAAAAyCsEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQDZ0rx5czVv3tz+/ODBg7LZbIqNjb2ldURHRyskJOSW7jMnkpOT1a1bNwUGBspms6lv3765vo+QkBBFR0fn+nZvdwX92ED+IOgAuSQ2NlY2m03u7u46evRopuXNmzdXtWrV8qEy3EqjRo1SbGysevbsqTlz5ujJJ5/M75JuO+fPn9eIESO0bt26/C4FFlAovwsArCYlJUVvvvmm3nvvvfwuJU8FBwfrwoULcnFxye9SCpSvvvpKDRs21PDhw/NsH7t375aTk3Xfp54/f14xMTGS5DCLeCPTp09XRkZGHlWF25V1/08B8kmtWrU0ffp0HTt2LM/2YYzRhQsX8mz72XFl9srZ2Tlf6yhoTp48KT8/vzzdh5ubGwHzKufOnZMkubi4yM3NLZ+rQUFD0AFy2SuvvKL09HS9+eabN+yblpamkSNHqnz58nJzc1NISIheeeUVpaSkOPQLCQnRAw88oC+//FJ169aVh4eHpk6dqnXr1slms+njjz9WTEyMSpUqJW9vbz388MNKTExUSkqK+vbtq+LFi8vLy0tPP/10pm3PnDlTd911l4oXLy43NzdVqVJFkydPvmHt116jc6WWrB7XXjfx+eefq1mzZvL09JS3t7dat26tX375JdM+lixZomrVqsnd3V3VqlXT4sWLb1jXtfuJiIiQt7e3fHx8VK9ePc2bN8+hz3//+1/VqVNHHh4eKlq0qDp37pzp1GN0dLS8vLx09OhRtW3bVl5eXipWrJj69++v9PR0h/EfOHBAK1assI/94MGD9tOaBw8edNjulXWuPkWzZ88edejQQYGBgXJ3d1fp0qX1+OOPKzEx0d4nq2t09u/fr0ceeUT+/v4qXLiwGjZsqBUrVmS5v48//lhvvPGGSpcuLXd3d919993au3fvDV/PESNGyGaz6bffflPnzp3l6+urYsWKaejQoTLG6MiRI3rooYfk4+OjwMBAjR071mH9S5cuadiwYapTp458fX3l6empZs2aae3atfY+Bw8eVLFixSRJMTEx9tdxxIgRDj+Lffv2qVWrVvL29lanTp3sy64+1oYPHy4nJyetWbPGoY4ePXrI1dVV27dvv+GYcfvj1BWQy0JDQ/XUU09p+vTpGjRokEqWLHndvt26ddOsWbP08MMP66WXXtL333+v0aNHKy4uLtMf9d27d6tjx4565pln1L17d1WqVMm+bPTo0fLw8NCgQYO0d+9evffee3JxcZGTk5P+/PNPjRgxQt99951iY2MVGhqqYcOG2dedPHmyqlatqjZt2qhQoUJatmyZevXqpYyMDD333HPZHnd4eLjmzJnj0JaQkKAXX3xRxYsXt7fNmTNHUVFRioyM1FtvvaXz589r8uTJatq0qbZu3Wr/Q7Vy5Up16NBBVapU0ejRoxUfH6+nn35apUuXzlY9sbGx6tKli6pWrarBgwfLz89PW7du1RdffKEnnnjC3ufpp59WvXr1NHr0aP3xxx+aMGGCNmzYoK1btzrMzKSnpysyMlINGjTQmDFjtHr1ao0dO1bly5dXz5497ePv16+fSpcurZdeekmS7H+0s+PSpUuKjIxUSkqKXnjhBQUGBuro0aNavny5EhIS5Ovrm+V6f/zxhxo3bqzz58+rd+/eCggI0KxZs9SmTRt98sknateunUP/N998U05OTurfv78SExP19ttvq1OnTvr++++zVedjjz2m8PBwvfnmm1qxYoVef/11+fv7a+rUqbrrrrv01ltvae7cuerfv7/q1aunO++8U5KUlJSkGTNmqGPHjurevbvOnj2r//znP4qMjNQPP/ygWrVqqVixYpo8ebJ69uypdu3aqX379pKkGjVq2PeflpamyMhINW3aVGPGjFHhwoWzrHPIkCFatmyZunbtqp07d8rb21tffvmlpk+frpEjR6pmzZrZGi9ucwZArpg5c6aRZDZv3mz27dtnChUqZHr37m1fHhERYapWrWp/vm3bNiPJdOvWzWE7/fv3N5LMV199ZW8LDg42kswXX3zh0Hft2rVGkqlWrZq5dOmSvb1jx47GZrOZ+++/36F/o0aNTHBwsEPb+fPnM40lMjLSlCtXzqEtIiLCRERE2J8fOHDASDIzZ87M8vXIyMgwDzzwgPHy8jK//PKLMcaYs2fPGj8/P9O9e3eHvidOnDC+vr4O7bVq1TJBQUEmISHB3rZy5UojKdMYrpWQkGC8vb1NgwYNzIULFzLVZYwxly5dMsWLFzfVqlVz6LN8+XIjyQwbNszeFhUVZSSZ1157zWFbtWvXNnXq1HFoCw4ONq1bt3Zou3JsHDhwwKH9ys9v7dq1xhhjtm7daiSZ//73v387vuDgYBMVFWV/3rdvXyPJfPPNN/a2s2fPmtDQUBMSEmLS09Md9hceHm5SUlLsfSdMmGAkmZ07d/7tfocPH24kmR49etjb0tLSTOnSpY3NZjNvvvmmvf3PP/80Hh4eDnWmpaU57PdKvxIlSpguXbrY206dOmUkmeHDh2eq4crPYtCgQVkuu/bY2Llzp3F1dTXdunUzf/75pylVqpSpW7euSU1N/duxwjo4dQXkgXLlyunJJ5/UtGnTdPz48Sz7fPbZZ5KkF1980aH9ykzAtacdQkNDFRkZmeW2nnrqKYdrNho0aCBjjLp06eLQr0GDBjpy5IjS0tLsbR4eHvb/TkxM1OnTpxUREaH9+/c7nC7JqZEjR2r58uWKjY1VlSpVJEmrVq1SQkKCOnbsqNOnT9sfzs7OatCggf0UxvHjx7Vt2zZFRUU5zGLcc8899m39nVWrVuns2bMaNGiQ3N3dHZbZbDZJ0pYtW3Ty5En16tXLoU/r1q1VuXLlTK+/JD377LMOz5s1a6b9+/dn8xW5sStj/fLLL3X+/Plsr/fZZ5+pfv36atq0qb3Ny8tLPXr00MGDB/Xrr7869H/66afl6upqf96sWTNJyvZYunXrZv9vZ2dn1a1bV8YYde3a1d7u5+enSpUqOWzT2dnZvt+MjAydOXNGaWlpqlu3rn766adsj1eSevbsma1+1apVU0xMjGbMmKHIyEidPn1as2bNUqFCnND4tyDoAHlkyJAhSktLu+61OocOHZKTk5PCwsIc2gMDA+Xn56dDhw45tIeGhl53X2XLlnV4fuUPZpkyZTK1Z2RkOASYDRs2qGXLlvL09JSfn5+KFSumV155RZL+cdD54osvFBMTo8GDB6tDhw729j179kiS7rrrLhUrVszhsXLlSp08eVKS7GOvUKFCpm1ffcruevbt2ydJf3s7/5V9ZLW9ypUrZ3r93d3dM52GKlKkiP78888b1pNdoaGhevHFFzVjxgwVLVpUkZGR+uCDD274czh06FCW4wgPD7cvv9q1x0uRIkUkKdtjyep4c3d3V9GiRTO1X7vNWbNmqUaNGnJ3d1dAQICKFSumFStW5OhYK1SoULZPYUrSgAEDVLNmTf3www8aPnx4tsIyrINIC+SRcuXKqXPnzpo2bZoGDRp03X5XZhhu5OqZl2td786n67UbYyRdDgR33323KleurHHjxqlMmTJydXXVZ599pnffffcf3ap74MABderUSffcc49ef/11h2VXtjdnzhwFBgZmWrcgv8u+mbvLrvczvnIh89XGjh2r6Oho/e9//9PKlSvVu3dvjR49Wt99912O/rj/nRsdF/9k/exs86OPPlJ0dLTatm2rAQMGqHjx4nJ2dtbo0aPt4TQ73NzccnR7/f79++0he+fOndleD9ZQcH+rABYwZMgQffTRR3rrrbcyLQsODlZGRob27Nljf+ctXb6wNCEhQcHBwXle37Jly5SSkqKlS5c6vEu/+i6YnLhw4YLat28vPz8/zZ8/P9Mfo/Lly0uSihcvrpYtW153O1fGfuWP09V27959wzqu7Ofnn3/ONGN27T52796tu+66K9M+cvP1vzJjkpCQ4NB+7UzLFdWrV1f16tU1ZMgQbdy4UU2aNNGUKVMyBccrgoODs3xddu3aZV9eEHzyyScqV66cFi1a5BD+rv3MoeyG/+zIyMhQdHS0fHx81LdvX40aNUoPP/yw/SJnWB+nroA8VL58eXXu3FlTp07ViRMnHJa1atVKkjR+/HiH9nHjxkm6fK1IXrvyLvzqd92JiYmaOXPmP9res88+q99++02LFy+2/3G/WmRkpHx8fDRq1CilpqZmWn7q1ClJUlBQkGrVqqVZs2Y5nNJYtWpVputNsnLvvffK29tbo0eP1sWLFx2WXRlr3bp1Vbx4cU2ZMsXhlvvPP/9ccXFxufr6XwleX3/9tb0tPT1d06ZNc+iXlJTkcP2UdDn0ODk5ZfpYgKu1atVKP/zwgzZt2mRvO3funKZNm6aQkJACc6omq+Pt+++/d6hbkv0uqmuD4T8xbtw4bdy4UdOmTdPIkSPVuHFj9ezZU6dPn77pbeP2wIwOkMdeffVVzZkzR7t371bVqlXt7TVr1lRUVJSmTZumhIQERURE6IcfftCsWbPUtm1btWjRIs9ru/fee+Xq6qoHH3xQzzzzjJKTkzV9+nQVL178uhdRX8+KFSs0e/ZsdejQQTt27NCOHTvsy7y8vNS2bVv5+Pho8uTJevLJJ3XHHXfo8ccfV7FixXT48GGtWLFCTZo00fvvvy/p8i3zrVu3VtOmTdWlSxedOXNG7733nqpWrark5OS/rcXHx0fvvvuuunXrpnr16umJJ55QkSJFtH37dp0/f16zZs2Si4uL3nrrLT399NOKiIhQx44d7beXh4SEqF+/fjl/Qa+jatWqatiwoQYPHqwzZ87I399fCxYsyBRqvvrqKz3//PN65JFHVLFiRaWlpWnOnDlydnZ2uNbpWoMGDdL8+fN1//33q3fv3vL399esWbN04MABffrppwXmU5QfeOABLVq0SO3atVPr1q114MABTZkyRVWqVHH4mXp4eKhKlSpauHChKlasKH9/f1WrVi3HX6ESFxenoUOHKjo6Wg8++KCkyx8pUKtWLfXq1Usff/xxro4PBVT+3fAFWMvVt5df68otsVffXm6MMampqSYmJsaEhoYaFxcXU6ZMGTN48GBz8eJFh35Z3bJszF+3C197O/L1arlye/CpU6fsbUuXLjU1atQw7u7uJiQkxLz11lvmww8/zHQ79I1uL7+yz6we197yu3btWhMZGWl8fX2Nu7u7KV++vImOjjZbtmxx6Pfpp5+a8PBw4+bmZqpUqWIWLVqU5S3E17N06VLTuHFj4+HhYXx8fEz9+vXN/PnzHfosXLjQ1K5d27i5uRl/f3/TqVMn8/vvvzv0iYqKMp6enpm2f+X1vNr1flb79u0zLVu2NG5ubqZEiRLmlVdeMatWrXK4vXz//v2mS5cupnz58sbd3d34+/ubFi1amNWrV2fax9W3bV/Z/sMPP2z8/PyMu7u7qV+/vlm+fLlDn+sdLzf6qIBrx3v18WPM9V+faz9SISMjw4waNcoEBwcbNzc3U7t2bbN8+fIsf6YbN240derUMa6urg63ml9vX1eWXdlOWlqaqVevnildurTDRxQY89ft9AsXLvzb8cIabMZk8+ozAACA20zBmM8EAADIAwQdAABgWQQdAABgWQQdAABgWQQdAABgWQQdAABgWXxgYAGQkZGhY8eOydvbO1c/+hwAACsyxujs2bMqWbLkDT8Qk6BTABw7dizTt0wDAIC/d+TIkRt+2S1BpwDw9vaWJLlWiZLN2TWfq4GVHV43Jr9LAICbdjYpSWGhZex/P/8OQacAuHK6yubsStBBnvLx8cnvEgAg12Tncg8uRgYAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0EG+a1y7vOaPe0a/fvaG/tz8vlpF1LjhOk3uqKB1cwbqxIZ39eOi4er4QINMfbo9cqe2/y9Gx799V6tm9tcdVYLzonzcZqZ/vF412gxTYJO+ahn9jn785eDf9l+y+ifVf3ikApv0VePH39DKDb84LDfGaNSU5ap83ysKatpPbXu9p32HT+bhCHA74DgrOAg6yHeFPdz0829HNeDthdnqX7ZkgBaOf1bf/Pib7uz0pqbMX6uJrz6huxqG2/u0u+cOvd63nd6a8bmaP/mWft5zVJ++95yKFvHKq2HgNrBo5Y8aMn6xBna7X+vmDFS1CqXU4YUPdOrM2Sz7f799v7oNiVXnhxpp/UeD1Dqipjr3n6Zf9x6z95kwe7WmLlyvcYMf16qZ/VXYw1UdXvhAF1NSb9WwUMBwnBUst1XQiY6Ols1mk81mk6urq8LCwvTaa68pLS0tv0vDTVi98Ve9MWW5Vqzbka3+Xdo31eFj8Ro6frF+O/iHpv/3ay39apt6PtHC3qfXE3dp9pKNmrfsO+0+cEIvjl6g8xcvqXObRnk1DNwGJs37Sk+1baxObRqpcrkgjRv8uAq7u+qjpZuy7D91wTrd3ShcvZ9sqUqhgXq15wOqWbmMpv93vaTL77KnzF+r/l0i1SqihqpVKKXJMU/pxOlErVi//VYODQUIx1nBclsFHUm67777dPz4ce3Zs0cvvfSSRowYoXfeeSfH20lPT1dGRkYeVIi8Vq96qNb9sNuhbc13capfPVSS5FLIWbUql3HoY4zR+h92q97/98G/z6XUNG3bdUTN61eytzk5OSmifiVt3nkgy3V+2HlAzetVdmi7q2G4Nu88KEk6dDRef8QnqXn9v/r4enmoTtUQbd5xMNfHgIKP46zgue2CjpubmwIDAxUcHKyePXuqZcuWWrp0qVJSUtS/f3+VKlVKnp6eatCggdatW2dfLzY2Vn5+flq6dKmqVKkiNzc3HT58WOvWrVP9+vXl6ekpPz8/NWnSRIcOHbKvN3nyZJUvX16urq6qVKmS5syZ41CPzWbTjBkz1K5dOxUuXFgVKlTQ0qVLb9XL8a9UPMAn0xTwqfgk+Xh5yN3NRQF+XipUyDlznzNJKh7gcytLRQESn5Cs9PQMFfP3dmgv5u+jk/FJWa5zMj5JxQKu7e9t7//H//97bZ/iAd7X3SasjeOs4Lntgs61PDw8dOnSJT3//PPatGmTFixYoB07duiRRx7Rfffdpz179tj7nj9/Xm+99ZZmzJihX375Rf7+/mrbtq0iIiK0Y8cObdq0ST169JDNZpMkLV68WH369NFLL72kn3/+Wc8884yefvpprV271qGGmJgYPfroo9qxY4datWqlTp066cyZM9etOSUlRUlJSQ4PAACQ+27boGOM0erVq/Xll1+qRo0amjlzpv773/+qWbNmKl++vPr376+mTZtq5syZ9nVSU1M1adIkNW7cWJUqVVJaWpoSExP1wAMPqHz58goPD1dUVJTKli0rSRozZoyio6PVq1cvVaxYUS+++KLat2+vMWPGONQSHR2tjh07KiwsTKNGjVJycrJ++OGH69Y+evRo+fr62h9lypTJmxfJok7GJ2V+txTgo6TkC7qYkqr4hGSlpaXn6B0VrC/Az0vOzk45mukrHuCjU/HX9j9r71/i//+9ts/J+LPMHv5LcZwVPLdd0Fm+fLm8vLzk7u6u+++/X4899pgefvhhpaenq2LFivLy8rI/1q9fr3379tnXdXV1VY0af9267O/vr+joaEVGRurBBx/UhAkTdPz4cfvyuLg4NWnSxGH/TZo0UVxcnEPb1dv09PSUj4+PTp68/m1/gwcPVmJiov1x5MiRf/x6/Btt3nlAEfUqObS1qF9ZP/z/+e/UtHRt23XEoY/NZtOd9Spe9xw5rM/VpZBqVS6j9Zv/unYrIyNDX2/+7brXbtWvHurQX5LWfr9L9aqHSJKCSwWoRICPQ5+k5Av68ZeDqlcjJNfHgIKP46zgue2CTosWLbRt2zbt2bNHFy5c0KxZs5ScnCxnZ2f9+OOP2rZtm/0RFxenCRMm2Nf18PCwn5a6YubMmdq0aZMaN26shQsXqmLFivruu+9yVJOLi4vDc5vN9rcXOru5ucnHx8fh8W/m6eGqahVLqVrFUpKk4JIBqlaxlEqXKCJJGvZcG00e8aS9/4eLvlVwqQDFvPCQKgSXUNeHm6lty9qaPO+vU4pX7np4vHUDVQwpoXGDHpOnh5vmLsvZzxbWcuVuvPnL//9uvDcX6tyFFHV6sKEk6dnhsxXz/v/s/Z95vLnWbPpV73+0Rr8dPKE3p63QtrjD6v5IhKTL/68/27GFxnz4hT5bv0O/7D2qniPmKLCor1pH1MyXMSL/cZwVLIXyu4Cc8vT0VFhYmENb7dq1lZ6erpMnT6pZs2Y53mbt2rVVu3ZtDR48WI0aNdK8efPUsGFDhYeHa8OGDYqKirL33bBhg6pUqXLT48BfaoUHa/nUPvbno17sIEmat/w7PRfzkUoU9VHpQH/78sPH4vVY3yka9WJ7PfN4cx07maDeb8zTV9/9NdO2eNVPKurnpVeeaa3iAd7a+dtRPdz7+p9jgX+H9vfW0emEZI2aukIn48+qesVS+mTic/bp/99PnJHTVW+GGtQsp+mvR+uNycs1ctIylStTTB+N6aEqYSXtffo81VLnL6So36j5Sky+oIY1y+uTib3k7uaSaf/4d+A4K1hsxhiT30VkV3R0tBISErRkyZJMyzp37qwNGzZo7Nixql27tk6dOqU1a9aoRo0aat26tWJjY9W3b18lJCTY1zlw4ICmTZumNm3aqGTJktq9e7eeeOIJjRw5Uj179tSSJUv06KOPasKECWrZsqWWLVuml19+WatXr1bz5s0lXU7aixcvVtu2be3b9fPz0/jx4xUdHZ2tcSUlJcnX11du1bvL5uz6z18g4Ab+3Px+fpcAADctKSlJJQJ8lZiYeMOzIrfdjM71zJw5U6+//rpeeuklHT16VEWLFlXDhg31wAMPXHedwoULa9euXZo1a5bi4+MVFBSk5557Ts8884wkqW3btpowYYLGjBmjPn36KDQ0VDNnzrSHHAAAULDdVjM6VsWMDm4VZnQAWEFOZnRuu4uRAQAAsougAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALKtQfheAvxxeN0Y+Pj75XQYsLHzAivwuAf8Cc3s1zu8SYHHnkpOy3ZcZHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFmFstNp6dKl2d5gmzZt/nExAAAAuSlbQadt27bZ2pjNZlN6evrN1AMAAJBrshV0MjIy8roOAACAXHdT1+hcvHgxt+oAAADIdTkOOunp6Ro5cqRKlSolLy8v7d+/X5I0dOhQ/ec//8n1AgEAAP6pHAedN954Q7GxsXr77bfl6upqb69WrZpmzJiRq8UBAADcjBwHndmzZ2vatGnq1KmTnJ2d7e01a9bUrl27crU4AACAm5HjoHP06FGFhYVlas/IyFBqamquFAUAAJAbchx0qlSpom+++SZT+yeffKLatWvnSlEAAAC5IVu3l19t2LBhioqK0tGjR5WRkaFFixZp9+7dmj17tpYvX54XNQIAAPwjOZ7Reeihh7Rs2TKtXr1anp6eGjZsmOLi4rRs2TLdc889eVEjAADAP5LjGR1JatasmVatWpXbtQAAAOSqfxR0JGnLli2Ki4uTdPm6nTp16uRaUQAAALkhx0Hn999/V8eOHbVhwwb5+flJkhISEtS4cWMtWLBApUuXzu0aAQAA/pEcX6PTrVs3paamKi4uTmfOnNGZM2cUFxenjIwMdevWLS9qBAAA+EdyPKOzfv16bdy4UZUqVbK3VapUSe+9956aNWuWq8UBAADcjBzP6JQpUybLDwZMT09XyZIlc6UoAACA3JDjoPPOO+/ohRde0JYtW+xtW7ZsUZ8+fTRmzJhcLQ4AAOBmZOvUVZEiRWSz2ezPz507pwYNGqhQocurp6WlqVChQurSpYvatm2bJ4UCAADkVLaCzvjx4/O4DAAAgNyXraATFRWV13UAAADkun/8gYGSdPHiRV26dMmhzcfH56YKAgAAyC05vhj53Llzev7551W8eHF5enqqSJEiDg8AAICCIsdB5+WXX9ZXX32lyZMny83NTTNmzFBMTIxKliyp2bNn50WNAAAA/0iOT10tW7ZMs2fPVvPmzfX000+rWbNmCgsLU3BwsObOnatOnTrlRZ0AAAA5luMZnTNnzqhcuXKSLl+Pc+bMGUlS06ZN9fXXX+dudQAAADchxzM65cqV04EDB1S2bFlVrlxZH3/8serXr69ly5bZv+QT+Cemf7xe7320Rifjk1StQim9NeAR1akact3+S1b/pFFTVujw8XiVK1NMI15oq3ubVLUvN8Zo9NQVmr1koxKTL6hBjXIaO+gxlS9b/BaMBgXVE42D1SWinIp6u2nX8SS9seQX7TySmGXfWc82VP3yAZna18ed1LMfbpYkjXqshtrVLeOw/JvdJ9VjxubcLx63jSVffK+Pl32rMwnJKh8cqBe6tFblsKy/9HrF6i1a+fU2HTzyhySpYrmS6trxHof+b32wSCvXb3VYr17NML35KndF30iOg87TTz+t7du3KyIiQoMGDdKDDz6o999/X6mpqRo3blxe1HhL2Ww2LV68mA8+vMUWrfxRQ8Yv1rhBj6lOtRBNmb9WHV74QJs/GaZi/t6Z+n+/fb+6DYnVsOfaKLJpNX3yxRZ17j9N6+YMVJWwy19FMmH2ak1duF6TRzypsiUDNGrKcnV44QN99/EQubu53OohogC4v2aQBj4YrhGf/qwdhxP0VLNQTe/WQK3eXqcz5y5l6t971o9yKfTXxLdfYRct7tdMX+w47tDv610n9erHO+zPL6Wl590gUOCt3bhTU2Z/rr7d26hyhdJatGKTBr4xS7Hj+6iIr1em/tt/PaC7mlRX1Uqt5epSSAv+941efn2W/jPuBRXz/+tO5nq1KujlXu3sz10K3dSN0/8aOT511a9fP/Xu3VuS1LJlS+3atUvz5s3T1q1b1adPnxxtKzo6Ot8CxYgRI1SrVq1M7cePH9f9999/6wv6l5s07ys91baxOrVppMrlgjRu8OMq7O6qj5ZuyrL/1AXrdHejcPV+sqUqhQbq1Z4PqGblMpr+3/WSLs/mTJm/Vv27RKpVRA1Vq1BKk2Oe0onTiVqxfvutHBoKkKg7Q/Xf749o8Zbfte9kskYs2qmLqelqX79Mlv0TL6Tq9NkU+6NxhaK6mJquL7c7Bp1LaRkO/ZIupN2K4aCA+mT5RrW6u67ua3GHQkoXV9/uD8rN1UVfrP0py/6v9H5ED0U2UFhIkMqWKqaXnm0rY4y27tzn0M+lkLP8/bztD28vj1sxnNtejoPOtYKDg9W+fXvVqFEjN+rJd4GBgXJzc8vvMv5VLqWmaduuI2pev5K9zcnJSRH1K2nzzgNZrvPDzgNqXq+yQ9tdDcO1eedBSdKho/H6Iz5Jzev/1cfXy0N1qoZo846DuT4GFHwuzjZVLeWrTXtO29uMkTbtOa1awX7Z2kaH+mX02bbjupDqOGNTv3yAvh3eUp8NiNDw9tXkV5gZw3+r1LQ0/bb/mO6oXs7e5uTkpDuql9evvx3J1jZSUlKVlpYub6/CDu3bfz2oDt3eVFSf8Ro/fakSz57P1dqtKlvzXhMnTsz2Bq/M9tys9evXa8CAAdq+fbv8/f0VFRWl119/3f79WhkZGRozZoymTZumI0eOqESJEnrmmWf06quvSpIGDhyoxYsX6/fff1dgYKA6deqkYcOGycXFRbGxsYqJiZEk+3d4zZw5U9HR0ZlOXe3cuVN9+vTRpk2bVLhwYXXo0EHjxo2Tl9fl6cfo6GglJCSoadOmGjt2rC5duqTHH39c48ePl4sLv+yyIz4hWenpGZlOURXz99Geg39kuc7J+CQVC7i2v7dOxidJkv74/3+v7VM84K8++Hfx83RVIWcnxSenOLTHJ6cotLjnDdevXsZXFYN8NOS/Oxzav911Sqt2ntDvZy6obEBh9b2/kqZ2ra+O729QhsnVIeA2kJh0XhkZGSri53iKqoifl44cO32dtRxNn7tSAf7eqnNVWKpXK0zNGoQrsHgRHTtxRv+Zv1qDR83We2/0kLPTTc9ZWFq2gs67776brY3ZbLZcCTpHjx5Vq1atFB0drdmzZ2vXrl3q3r273N3dNWLECEnS4MGDNX36dL377rtq2rSpjh8/rl27dtm34e3trdjYWJUsWVI7d+5U9+7d5e3trZdfflmPPfaYfv75Z33xxRdavXq1JMnX1zdTHefOnVNkZKQaNWqkzZs36+TJk+rWrZuef/55xcbG2vutXbtWQUFBWrt2rfbu3avHHntMtWrVUvfu3bMcX0pKilJS/vplm5TEH16goOtQv4x2H0/KdOHyZ1edxtpz4qx2H0/SqsF3qX75AH23N/5Wl4nb3PwlX2vthp0aO6KLXF3/erN8V5O/zpqUKxuocsGBevKFd7X9lwO6o3r5/Cj1tpGtoHPgQNanD/LKpEmTVKZMGb3//vuy2WyqXLmyjh07poEDB2rYsGE6d+6cJkyYoPfff9/+PVzly5dX06ZN7dsYMmSI/b9DQkLUv39/LViwQC+//LI8PDzk5eWlQoUKKTAw8Lp1zJs3TxcvXtTs2bPl6Xn5Hd/777+vBx98UG+99ZZKlCgh6fK3u7///vtydnZW5cqV1bp1a61Zs+a6QWf06NH2GSVIAX5ecnZ20qkzZx3aT51JUvGArL9SpHiAj07FX9v/rL1/if//91T8WQUW/SvEnow/q+oVs77zAdaWcO6S0tIzFODleGo6wMtNp8+mXGetyzxcnNWqZkm9t/K3G+7n9zMXdCY5RWWLehJ0/oV8fQrLyclJfyYkO7T/mZAsf7/MFyJf7eOl32r+km/0ztBolQ++/t8mSSpZwl++3oV19MQZgs4NFMj5rri4ODVq1Mh+WkmSmjRpouTkZP3++++Ki4tTSkqK7r777utuY+HChWrSpIkCAwPl5eWlIUOG6PDhwzmuo2bNmvaQc6WOjIwM7d69295WtWpVOTs7258HBQXp5MmT193u4MGDlZiYaH8cOZK987ZW5epSSLUql9H6zX+9phkZGfp682+qVz00y3XqVw916C9Ja7/fpXrVQyRJwaUCVCLAx6FPUvIF/fjLQdWrEZLrY0DBl5pu9MvRRDUMK2pvs9mkhmEB2nYo4W/XjawZJNdCTlr209Eb7qeEr7v8CrvqVNLFmy0ZtyGXQoVUsVxJbf15v70tIyNDW3/eryoVs77oXZIW/O8bffTpOr35ylOqVL7UDfdzKj5RSckXFFDk78MTCmjQuREPj7+/0nzTpk3q1KmTWrVqpeXLl2vr1q169dVXM30BaW659locm82mjIyM6/Z3c3OTj4+Pw+PfrtcTd2n2ko2av/w77T5wQi++uVDnLqSo04MNJUnPDp+tmPf/Z+//zOPNtWbTr3r/ozX67eAJvTlthbbFHVb3RyIkXf4ZPNuxhcZ8+IU+W79Dv+w9qp4j5iiwqK9aR9TMlzEi/836+oAeaVBGD9UppXLFvTS8fTV5uBbS4s2X32y8+XhN9bu/Uqb1OtQrozW//KGE86kO7YVdndW/dWXVLOunkkU81DAsQB9E19Xh+HP6dnf2rseA9Tz8QGOtWPOjvly3VYd+P6nxM5bpYsolRTa/Q5L05vufaMa8lfb+85d8rdiFa9S/ZzsFFvfTmYSzOpNwVhcuXp5pvHAxRVPnfKFffzuiEyf/1E8792no2/NUMtBfdWtWyJcx3k4K5E344eHh+vTTT2WMsc/qbNiwQd7e3ipdurSKFy8uDw8PrVmzRt26dcu0/saNGxUcHGy/MFmSDh065NDH1dVV6el//1kX4eHhio2N1blz5+yzOhs2bJCTk5MqVcr8yxD/XPt76+h0QrJGTV3x/6eXSumTic/ZT0X9fuKMnK6a4WtQs5ymvx6tNyYv18hJy1SuTDF9NKaH/TN0JKnPUy11/kKK+o2ar8TkC2pYs7w+mdiLz9D5F/t8+3EV8XRV78iKKurtprhjSeox4wfFJ19+ExTk56EM43gFcUgxT9Ut56+u077PtL30DKNKQT5qW7e0vN1ddCrpojb8dloTv9yt1PTrv9mBtbVoXF2JSecU+/Ea/ZmQrPIhQXrzlafsp65Onk6UzfbXPMOyVZuVmpaumHELHLbz1MMtFPXoXXJyctL+w39o5fptSj53UQH+3qpbI0zRj90tV5cC+We8QLEZY/LtvoDo6GgdOnQo08XORYoUUZUqVfT000/r+eef1+7du9WtWzc999xz9ouRY2JiNGHCBI0fP15NmjTRqVOn9Msvv6hr165aunSpOnTooDlz5qhevXpasWKFYmJilJ6eroSEBEmXr7/p0aOHvv32W5UuXVre3t5yc3NzuOvq/PnzCgsLU+PGjTVixAidOnVK3bp1U7NmzewXI1+562rJkiX2+vv27att27Zp3bp12XodkpKS5Ovrqz/iE5ndQZ4KH7Aiv0vAv8DcXo3zuwRY3LnkJN17R4gSE2/8dzPfo+C6detUu3Zth7auXbvqs88+04ABA1SzZk35+/ura9euDhcYDx06VIUKFdKwYcN07NgxBQUF6dlnn5UktWnTRv369dPzzz+vlJQUtW7dWkOHDrWHJEnq0KGDFi1apBYtWighIcF+e/nVChcurC+//FJ9+vRRvXr1HG4vBwAABd8/mtH55ptvNHXqVO3bt0+ffPKJSpUqpTlz5ig0NNThzidkDzM6uFWY0cGtwIwO8lpOZnRyfDHyp59+qsjISHl4eGjr1q32z4NJTEzUqFGj/lnFAAAAeSDHQef111/XlClTNH36dIe7jZo0aaKffsr6ezwAAADyQ46Dzu7du3XnnXdmavf19bVf6AsAAFAQ5DjoBAYGau/evZnav/32W5UrVy6LNQAAAPJHjoNO9+7d1adPH33//fey2Ww6duyY5s6dq/79+6tnz555USMAAMA/kuPbywcNGqSMjAzdfffdOn/+vO688065ubmpf//+euGFF/KiRgAAgH8kx0HHZrPp1Vdf1YABA7R3714lJyerSpUq8vLi+zYAAEDB8o8/MNDV1VVVqlTJzVoAAAByVY6DTosWLRy+VfxaX3311U0VBAAAkFtyHHRq1arl8Dw1NVXbtm3Tzz//rKioqNyqCwAA4KblOOhc+wWcV4wYMULJyck3XRAAAEBuyfHt5dfTuXNnffjhh7m1OQAAgJuWa0Fn06ZNcnd3z63NAQAA3LQcn7pq3769w3NjjI4fP64tW7Zo6NChuVYYAADAzcpx0PH19XV47uTkpEqVKum1117Tvffem2uFAQAA3KwcBZ309HQ9/fTTql69uooUKZJXNQEAAOSKHF2j4+zsrHvvvZdvKQcAALeFHF+MXK1aNe3fvz8vagEAAMhVOQ46r7/+uvr376/ly5fr+PHjSkpKcngAAAAUFNm+Rue1117TSy+9pFatWkmS2rRp4/BVEMYY2Ww2paen536VAAAA/0C2g05MTIyeffZZrV27Ni/rAQAAyDXZDjrGGElSREREnhUDAACQm3J0jc7ffWs5AABAQZOjz9GpWLHiDcPOmTNnbqogAACA3JKjoBMTE5Ppk5EBAAAKqhwFnccff1zFixfPq1oAAAByVbav0eH6HAAAcLvJdtC5ctcVAADA7SLbp64yMjLysg4AAIBcl+OvgAAAALhdEHQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlFcrvAvCXS2kZupSWkd9lwMLi3mmd3yXgX6BI05fzuwRYnElLyXZfZnQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlFcrvAoArPvzka02a+5VOnklSlbBSGvXiw7qjavB1+y9ds1VvTVuhIyfOKLR0MQ19ro1aNq5qX/7OjM+0ZNVPOnoyQa4uzqpRqYwGP/uA6lQNuQWjQUE1/eP1eu+jNToZn6RqFUrprQGP/O0xsWT1Txo1ZYUOH49XuTLFNOKFtrq3yV/HmTFGo6eu0OwlG5WYfEENapTT2EGPqXzZ4rdgNCiourVvpBc6Rqi4v7d+3ndcA9/9n36KO5Jl30LOTur35F3qeH8dBRX10d4jpzRi8mda8/1v9j7b/ztIZYP8M607Y9FGDRi3JK+GYQnM6Py/2NhY+fn55XcZ/1pLVv+k4RMX66Wu92lV7ABVrVBKj/ebpFNnzmbZf/OO/Xp2+Cw98WAjrZ71su6/s4aiB85Q3L5j9j7lyhTXqJce0bqPBmnplL4qE+Svx/pM0uk/s94mrG/Ryh81ZPxiDex2v9bNGahqFUqpwwsfXPc4+377fnUbEqvODzXS+o8GqXVETXXuP02/7v3rOJswe7WmLlyvcYMf16qZ/VXYw1UdXvhAF1NSb9WwUMC0u6umXn/+Qb01c7Wad52gn/ce16fjuqqon2eW/Yf0iFT0Qw008N3/qeGTYzVzyXeaMypK1SuUtPe5q/t7qtTmNfujbd9pkqQla3fckjHdziwXdI4cOaIuXbqoZMmScnV1VXBwsPr06aP4+Hh7n5CQEI0fPz7/ikQmU+avVec2jdXxgYaqFBqkd15+VB5urpq//Lss+0/7eL1aNAjXc53vVsWQQA16prWqVyqtDz/5xt6nQ2RdRdSvpJBSRVW5XJBe69NOZ89ddPgjhX+XSfO+0lNtG6tTm0aqXC5I4wY/rsLurvpo6aYs+09dsE53NwpX7ydbqlJooF7t+YBqVi6j6f9dL+nybM6U+WvVv0ukWkXUULUKpTQ55imdOJ2oFeu338qhoQDp9XgzzV72veZ9tkW7D57Ui+8s0vmLqer8QL0s+z8aWUfvzvlKq77bpUPHzujDJd9p1aZdev7xO+194hPO6eSZZPsjsnG49v9+Whu27r9Vw7ptWSro7N+/X3Xr1tWePXs0f/587d27V1OmTNGaNWvUqFEjnTlz5pbXlJrKu7obuZSaph27j6hZvUr2NicnJ91Zr5K2/Hwgy3V+/Pmg7qxX0aGtRYPw6/a/lJqmOUs2ysfLQ1UrlMq94nHbuJSapm27jqh5fcfjLKJ+JW3emfVx88POA2per7JD210Nw7V550FJ0qGj8fojPknN6//Vx9fLQ3WqhmjzjoO5PgYUfC6FnFWrYimt27LX3maM0fote1TvOqfi3VycdTElzaHtYkqqGtYIue4+Hr33Ds1dsTnX6rYySwWd5557Tq6urlq5cqUiIiJUtmxZ3X///Vq9erWOHj2qV199Vc2bN9ehQ4fUr18/2Ww22Ww2h218+eWXCg8Pl5eXl+677z4dP37cYfmMGTMUHh4ud3d3Va5cWZMmTbIvO3jwoGw2mxYuXKiIiAi5u7tr7ty5t2Tst7MzCeeUnp6hYv7eDu3F/L11Mj7rUwon45NUzN/nhv1XfvuzQu/qr7IRL2nqgnX6eEIvBfh55e4AcFuIT0i+znHmo5PxSVmuczI+ScUCsjouL/f/4///vbZP8QDv624T1hbg66lChZwznQ49dSZZxa85Tq746off1OvxZipXuqhsNpua162gByKqqUSAT5b9W99ZVb5e7pr32Y+5Xr8VWeZi5DNnzujLL7/UG2+8IQ8PD4dlgYGB6tSpkxYuXKg9e/aoVq1a6tGjh7p37+7Q7/z58xozZozmzJkjJycnde7cWf3797eHlblz52rYsGF6//33Vbt2bW3dulXdu3eXp6enoqKi7NsZNGiQxo4dq9q1a8vd3T1TrSkpKUpJSbE/T0riF2JeaVKngr6aNVDxicn66H+b1H3ITH0+46VMf+wAIL8MmrBUE17uoB/m9pcxRgeOndG8z7aoU+usT3V1bl1Pq7/frROE6WyxTNDZs2ePjDEKDw/Pcnl4eLj+/PNPpaeny9nZWd7e3goMDHTok5qaqilTpqh8+fKSpOeff16vvfaaffnw4cM1duxYtW/fXpIUGhqqX3/9VVOnTnUIOn379rX3ycro0aMVExPzj8dqNf5+nnJ2dsriHdDZ674DKh7go1Nnkm7Y39PDTaFliim0TDHVrRaqho+M1Lxlm9Qn6t7cHQQKvAA/r+scZ0kqfp13zsUDfHQqPqvj8nL/K++4T8WfVWBRX3ufk/FnVb1i6dwsH7eJ+MRzSktLz2Lm0Ou6M9TxCefU+ZXZcnMtJH+fwjp+Okkjet6vg8fiM/UtU8JPzetW0JOvzs6T+q3IUqeupMvnQv+pwoUL20OOJAUFBenkyZOSpHPnzmnfvn3q2rWrvLy87I/XX39d+/btc9hO3bp1/3Y/gwcPVmJiov1x5EjWtxz+W7i6FFKNSmX0zZa/bqXMyMjQN1t2q2610CzXqVMtxKG/JK3/Ydd1+9u3azJ0KTXtb/vAmlxdCqlW5TJav3m3vS0jI0Nfb/5N9apnfdzUrx7q0F+S1n6/S/Wqh0iSgksFqESAj0OfpOQL+vGXg6p3nesrYG2paena9ttRRdQJs7fZbDbdWSdMm3859LfrplxK0/HTSSrk7KQHI6rr829+zdTnidb1dOrPZK3ctCvXa7cqy8zohIWFyWazKS4uTu3atcu0PC4uTkWKFFGxYsWuuw0XFxeH5zabzR6ckpOTJUnTp09XgwYNHPo5Ozs7PPf0zPoWwivc3Nzk5ub2t33+bZ7t2EK9R36kWpXLqHbVYE1bsE7nL17S4w9cfq2fj5mjwGK+GtKrjSSpx6MRattroibP+0otG1fVktU/avuuIxoz6HFJ0rkLKRofu1KRzaqpRICvziQm68NPvtGJU4l68K7a+TZO5K9eT9ylXjFzVDu8rO6oGqLJ89fq3IUUdXqwoSTp2eGzFVTMV8Off0iS9MzjzfXAM+P1/kdrdG/Tqlq08kdtizus8a90lHT5d8SzHVtozIdfqFyZYgouFaBRU1YosKivWkfUzLdxIn9NWvCNJr36qLbu+l0/xR1Rz0ebytPDVXNXbJEkTR7ymI6fStRrU7+QJNWpUkZBRX21c+8xlSzqo4Fd7pGTk00T5q1z2K7NZlOnVnW14IsflZ6ecauHdduyTNAJCAjQPffco0mTJqlfv34O1+mcOHFCc+fO1VNPPSWbzSZXV1elp6fnaPslSpRQyZIltX//fnXq1Cm3y//Xa9vyDsX/may3Z3ymk/FJqlqhtOa/21PF//+C46N//Cknp78uHK9Xo5wmx0TpzWkrNGrKMoWWKa7Yt7opvPzlz51wdnLS3kN/6OPPftCZxGQV8fVUrfCy+t/kPqpcLihfxoj81/7eOjqdkKxRU1f8/+mlUvpk4nP2U1G/nzgjp6tuUGhQs5ymvx6tNyYv18hJy1SuTDF9NKaHqoT99fkmfZ5qqfMXUtRv1HwlJl9Qw5rl9cnEXnJ3c8m0f/w7LP5qu4r6eeqVbvequL+3du49podf+o9O/Xn5DXPpEn7KyPjr7IObq4te7R6pkJL+OnfhklZ9t0vPjlyopOSLDtttXjdMZQKL6CPutsoRm7mZcz0FzJ49e9S4cWOFh4fr9ddfV2hoqH755RcNGDBAKSkp+u677+Tv7697771XHh4emjRpktzc3FS0aFHFxsaqb9++SkhIsG9vyZIlateunX1WZ8aMGerdu7fefPNN3XfffUpJSdGWLVv0559/6sUXX9TBgwcVGhqqrVu3qlatWtmuOykpSb6+vjryx5/y8cn6WgEgN7gWstzZahRARZq+nN8lwOJMWopSfpyoxMTEG/7dtNRvvQoVKmjLli0qV66cHn30UZUvX149evRQixYttGnTJvn7X/747Ndee00HDx5U+fLl//ZU1rW6deumGTNmaObMmapevboiIiIUGxur0NC/vy4EAADkD0vN6NyumNHBrcKMDm4FZnSQ1/61MzoAAABXI+gAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLKpTfBUAyxkiSzp5NyudKYHWuhXhvg7xn0lLyuwRYnEm/fIxd+fv5dwg6BcDZs2clSVXCgvO5EgAAbh9nz56Vr6/v3/axmezEIeSpjIwMHTt2TN7e3rLZbPldzm0hKSlJZcqU0ZEjR+Tj45Pf5cCiOM5wK3Cc5ZwxRmfPnlXJkiXl5PT3M9XM6BQATk5OKl26dH6XcVvy8fHhFwPyHMcZbgWOs5y50UzOFZywBwAAlkXQAQAAlkXQwW3Jzc1Nw4cPl5ubW36XAgvjOMOtwHGWt7gYGQAAWBYzOgAAwLIIOgAAwLIIOgAAwLIIOgBwk2w2m5YsWZLfZeA2ExsbKz8/v/wuw/IIOshz0dHRstlsstlscnV1VVhYmF577TWlpaXld2m4DUVHR6tt27b5su8RI0aoVq1amdqPHz+u+++//9YXhALhyJEj6tKli0qWLClXV1cFBwerT58+io+Pt/cJCQnR+PHj86/IfzGCDm6J++67T8ePH9eePXv00ksvacSIEXrnnXdyvJ309HRlZGTkQYXAPxcYGMitwf9S+/fvV926dbVnzx7Nnz9fe/fu1ZQpU7RmzRo1atRIZ86cueU1paam3vJ9FmQEHdwSbm5uCgwMVHBwsHr27KmWLVtq6dKlSklJUf/+/VWqVCl5enqqQYMGWrdunX29K1O7S5cuVZUqVeTm5qbDhw9r3bp1ql+/vjw9PeXn56cmTZro0KFD9vUmT56s8uXLy9XVVZUqVdKcOXMc6rHZbJoxY4batWunwoULq0KFClq6dOmtejmQR9avX6/69evLzc1NQUFBGjRokMPMYUZGht5++22FhYXJzc1NZcuW1RtvvGFfPnDgQFWsWFGFCxdWuXLlNHToUPsfjdjYWMXExGj79u32GcrY2FhJmU9d7dy5U3fddZc8PDwUEBCgHj16KDk52b78yqzUmDFjFBQUpICAAD333HP8gboNPffcc3J1ddXKlSsVERGhsmXL6v7779fq1at19OhRvfrqq2revLkOHTqkfv362Y+dq3355ZcKDw+Xl5eX/U3h1WbMmKHw8HC5u7urcuXKmjRpkn3ZwYMHZbPZtHDhQkVERMjd3V1z5869JWO/bRggj0VFRZmHHnrIoa1NmzbmjjvuMN26dTONGzc2X3/9tdm7d6955513jJubm/ntt9+MMcbMnDnTuLi4mMaNG5sNGzaYXbt2mcTEROPr62v69+9v9u7da3799VcTGxtrDh06ZIwxZtGiRcbFxcV88MEHZvfu3Wbs2LHG2dnZfPXVV/b9SzKlS5c28+bNM3v27DG9e/c2Xl5eJj4+/pa9LvhnsjqejDHm999/N4ULFza9evUycXFxZvHixaZo0aJm+PDh9j4vv/yyKVKkiImNjTV79+4133zzjZk+fbp9+ciRI82GDRvMgQMHzNKlS02JEiXMW2+9ZYwx5vz58+all14yVatWNcePHzfHjx8358+fN8ZcPp4WL15sjDEmOTnZBAUFmfbt25udO3eaNWvWmNDQUBMVFeUwBh8fH/Pss8+auLg4s2zZMlO4cGEzbdq0XH+9kHfi4+ONzWYzo0aNynJ59+7dTZEiRczp06dN6dKlzWuvvWY/doz56/dby5YtzebNm82PP/5owsPDzRNPPGHfxkcffWSCgoLMp59+avbv328+/fRT4+/vb2JjY40xxhw4cMBIMiEhIfY+x44dy/vB30YIOshzV/9hysjIMKtWrTJubm4mOjraODs7m6NHjzr0v/vuu83gwYONMZd/EUgy27Ztsy+Pj483ksy6deuy3F/jxo1N9+7dHdoeeeQR06pVK/tzSWbIkCH258nJyUaS+fzzz29qrMh71ws6r7zyiqlUqZLJyMiwt33wwQfGy8vLpKenm6SkJOPm5uYQbG7knXfeMXXq1LE/Hz58uKlZs2amflcHnWnTppkiRYqY5ORk+/IVK1YYJycnc+LECfsYgoODTVpamr3PI488Yh577LFs14b899133zn87K81btw4I8n88ccfJjg42Lz77rsOy6/8ftu7d6+97YMPPjAlSpSwPy9fvryZN2+ew3ojR440jRo1Msb8FXTGjx+fO4OyIL69HLfE8uXL5eXlpdTUVGVkZOiJJ57Qww8/rNjYWFWsWNGhb0pKigICAuzPXV1dVaNGDftzf39/RUdHKzIyUvfcc49atmypRx99VEFBQZKkuLg49ejRw2GbTZo00YQJExzart6mp6enfHx8dPLkyVwbM26tuLg4NWrUyOG0QJMmTZScnKzff/9dJ06cUEpKiu6+++7rbmPhwoWaOHGi9u3bp+TkZKWlpeX426Tj4uJUs2ZNeXp6OtSRkZGh3bt3q0SJEpKkqlWrytnZ2d4nKChIO3fuzNG+UDCYm/iCgcKFC6t8+fL250FBQfbfQ+fOndO+ffvUtWtXde/e3d4nLS0t0zd3161b9x/XYHUEHdwSLVq00OTJk+Xq6qqSJUuqUKFCWrhwoZydnfXjjz86/MKXJC8vL/t/e3h4ZDqnPXPmTPXu3VtffPGFFi5cqCFDhmjVqlVq2LBhtmtycXFxeG6z2bjQ2cI8PDz+dvmmTZvUqVMnxcTEKDIyUr6+vlqwYIHGjh2bJ/Vw/N3+wsLCZLPZFBcXp3bt2mVaHhcXpyJFiqhYsWLX3UZWx8GV4HTluq7p06erQYMGDv2u/Z15dbCGIy5Gxi3h6empsLAwlS1bVoUKXc7XtWvXVnp6uk6ePKmwsDCHR2Bg4A23Wbt2bQ0ePFgbN25UtWrVNG/ePElSeHi4NmzY4NB3w4YNqlKlSu4PDAVGeHi4Nm3a5PDuesOGDfL29lbp0qVVoUIFeXh4aM2aNVmuv3HjRgUHB+vVV19V3bp1VaFCBYcL3KXLs4vp6ek3rGP79u06d+6cQx1OTk6qVKnSTYwQBU1AQIDuueceTZo0SRcuXHBYduLECc2dO1ePPfaY/aM1bnTsXKtEiRIqWbKk9u/fn+l3ZGhoaG4OxdIIOsg3FStWVKdOnfTUU09p0aJFOnDggH744QeNHj1aK1asuO56Bw4c0ODBg7Vp0yYdOnRIK1eu1J49exQeHi5JGjBggGJjYzV58mTt2bNH48aN06JFi9S/f/9bNTTkscTERG3bts3h0aNHDx05ckQvvPCCdu3apf/9738aPny4XnzxRTk5Ocnd3V0DBw7Uyy+/rNmzZ2vfvn367rvv9J///EeSVKFCBR0+fFgLFizQvn37NHHiRC1evNhhvyEhITpw4IC2bdum06dPKyUlJVNtnTp1kru7u6KiovTzzz9r7dq1euGFF/Tkk0/aT1vBOt5//32lpKQoMjJSX3/9tY4cOaIvvvhC99xzj0qVKmW/qy8kJERff/21jh49qtOnT2d7+zExMRo9erQmTpyo3377TTt37tTMmTM1bty4vBqS9eTzNUL4F7jexaPGGHPp0iUzbNgwExISYlxcXExQUJBp166d2bFjhzHm8sV6vr6+DuucOHHCtG3b1gQFBRlXV1cTHBxshg0bZtLT0+19Jk2aZMqVK2dcXFxMxYoVzezZsx22oSwuIPT19TUzZ8682eEij0VFRRlJmR5du3Y169atM/Xq1TOurq4mMDDQDBw40KSmptrXTU9PN6+//roJDg42Li4upmzZsg53zAwYMMAEBAQYLy8v89hjj5l3333X4fi7ePGi6dChg/Hz8zOS7MfLtcfTjh07TIsWLYy7u7vx9/c33bt3N2fPnnUYw7X/T/Tp08dERETk5kuFW+TgwYMmKirKlChRwri4uJgyZcqYF154wZw+fdreZ9OmTaZGjRrGzc3NXPnTm9Xvt8WLF5tr/zTPnTvX1KpVy7i6upoiRYqYO++80yxatMgY89fFyFu3bs3TMd7ObMbcxFVUAAAABRinrgAAgGURdAAAgGURdAAAgGURdAAAgGURdAAAgGURdAAAgGURdAAAgGURdAAAgGURdADc1qKjo9W2bVv78+bNm6tv3763vI5169bJZrMpISHhun1sNpuWLFmS7W2OGDFCtWrVuqm6Dh48KJvNpm3btt3UdoDbFUEHQK6Ljo6WzWazf5lhWFiYXnvtNaWlpeX5vhctWqSRI0dmq292wgmA21uh/C4AgDXdd999mjlzplJSUvTZZ5/pueeek4uLiwYPHpyp76VLl+Tq6por+/X398+V7QCwBmZ0AOQJNzc3BQYGKjg4WD179lTLli21dOlSSX+dbnrjjTdUsmRJVapUSZJ05MgRPfroo/Lz85O/v78eeughHTx40L7N9PR0vfjii/Lz81NAQIBefvllXft1fdeeukpJSdHAgQNVpkwZubm5KSwsTP/5z3908OBBtWjRQpJUpEgR2Ww2RUdHS5IyMjI0evRohYaGysPDQzVr1tQnn3zisJ/PPvtMFStWlIeHh1q0aOFQZ3YNHDhQFStWVOHChVWuXDkNHTpUqampmfpNnTpVZcqUUeHChfXoo48qMTHRYfmMGTMUHh4ud3d3Va5cWZMmTcpxLYBVEXQA3BIeHh66dOmS/fmaNWu0e/durVq1SsuXL1dqaqoiIyPl7e2tb775Rhs2bJCXl5fuu+8++3pjx45VbGysPvzwQ3377bc6c+aMFi9e/Lf7feqppzR//nxNnDhRcXFxmjp1qry8vFSmTBl9+umnkqTdu3fr+PHjmjBhgiRp9OjRmj17tqZMmaJffvlF/fr1U+fOnbV+/XpJlwNZ+/bt9eCDD2rbtm3q1q2bBg0alOPXxNvbW7Gxsfr11181YcIETZ8+Xe+++65Dn7179+rjjz/WsmXL9MUXX2jr1q3q1auXffncuXM1bNgwvfHGG4qLi9OoUaM0dOhQzZo1K8f1AJaUz9+eDsCCoqKizEMPPWSMMSYjI8OsWrXKuLm5mf79+9uXlyhRwqSkpNjXmTNnjqlUqZLJyMiwt6WkpBgPDw/z5ZdfGmOMCQoKMm+//bZ9eWpqqildurR9X8YYExERYfr06WOMMWb37t1Gklm1alWWda5du9ZIMn/++ae97eLFi6Zw4cJm48aNDn27du1qOnbsaIwxZvDgwaZKlSoOywcOHJhpW9eSZBYvXnzd5e+8846pU6eO/fnw4cONs7Oz+f333+1tn3/+uXFycjLHjx83xhhTvnx5M2/ePIftjBw50jRq1MgYY8yBAweMJLN169br7hewMq7RAZAnli9fLi8vL6WmpiojI0NPPPGERowYYV9evXp1h+tytm/frr1798rb29thOxcvXtS+ffuUmJio48ePq0GDBvZlhQoVUt26dTOdvrpi27ZtcnZ2VkRERLbr3rt3r86fP6977rnHof3SpUuqXbu2JCkuLs6hDklq1KhRtvdxxcKFCzVx4kTt27dPycnJSktLk4+Pj0OfsmXLqlSpUg77ycjI0O7du+Xt7a19+/apa9eu6t69u71PWlqafH19c1wPYEUEHQB5okWLFpo8ebJcXV1VsmRJFSrk+OvG09PT4XlycrLq1KmjuXPnZtpWsWLF/lENHh4eOV4nOTlZkrRixQqHgCFdvu4ot2zatEmdOnVSTEyMIiMj5evrqwULFmjs2LE5rnX69OmZgpezs3Ou1Qrczgg6APKEp6enwsLCst3/jjvu0MKFC1W8ePFMsxpXBAUF6fvvv9edd94p6fLMxY8//qg77rgjy/7Vq1dXRkaG1q9fr5YtW2ZafmVGKT093d5WpUoVubm56fDhw9edCQoPD7dfWH3Fd999d+NBXmXjxo0KDg7Wq6++am87dOhQpn6HDx/WsWPHVLJkSft+nJycVKlSJZUoUUIlS5bU/v371alTpxztH/i34GJkAAVCp06dVLRoUT300EP65ptvdODAAa1bt069e/fW77//Lknq06eP3nzzTS1ZskS7du1Sr169/vYzcEJCQhQVFaUuXbpoyZIl9m1+/PHHkqTg4GDZbDYtX75cp06dUnJysry9vdW/f3/169dPs2bN0r59+/TTTz/pvffes1/g++yzz2rPnj0aMGCAdu/erXnz5ik2NjZH461QoYIOHz6sBQsWaN++fZo4cWKWF1a7u7srKipK27dv1zfffKPevXvr0UcfVWBgoCQpJiZGo0eP1sSJE/Xbb79p586dmjlzpsaNG5ejegCrIugAKBAKFy6sr7/+WmXLllX79u0VHh6url276uLFi/YZnpdeeklPPvmkoqKi1KhRI3l7e6tdu3Z/u93Jkyfr4YcfVq9evVS5cmV1795d586dkySVKlVKMTExGjRokEqUKKHnn39ekjRy5EgNHTpUo0ePVnh4uO677z6tWLFCoaGhki5fN/Ppp59qyZIlqlmzpqZMmaJRo0blaLxt2rRRv3799Pzzz6tWrVrauHGjhg4dmqlfWFiY2rdvr1atWunee+9VjRo1HG4f79atm2bMmKGZM2eqevXqioiIUGxsrL1W4N/OZq53FR8AAMBtjhkdAABgWQQdAABgWQQdAABgWQQdAABgWQQdAABgWQQdAABgWQQdAABgWQQdAABgWQQdAABgWQQdAABgWQQdAABgWf8HosUbw6/GSxgAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "\n",
    "labels = ['Person', 'Location', 'Other']\n",
    "\n",
    "def plot_confusion_matrix(y_preds, y_true, labels):\n",
    "    cm = confusion_matrix(y_true, y_preds, normalize=\"true\")\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot(cmap=\"Blues\", values_format=\".2f\", ax=ax, colorbar=False)\n",
    "    plt.title(\"Normalized confusion matrix\")\n",
    "    plt.show()\n",
    "\n",
    "y_preds = np.argmax(preds_output.predictions, axis=1)\n",
    "y_valid = np.array(segments_encoded[\"test\"][\"label\"])\n",
    "\n",
    "plot_confusion_matrix(y_preds, y_valid, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "label2idx = {\n",
    "    'Person': 0,\n",
    "    'Location': 1,\n",
    "    'Other': 2\n",
    "}\n",
    "\n",
    "idx2label = {\n",
    "    0: 'Person',\n",
    "    1: 'Location',\n",
    "    2: 'Other'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7a6c748a31654b25970e9af9c19cd8d5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "edition = 1\n",
    "segments_ed1 = await load_segments(edition, range(1, 1001), get_all=False)\n",
    "\n",
    "segments_ed1_list = []\n",
    "\n",
    "for article, value_list in segments_ed1.items():\n",
    "    for value in value_list:\n",
    "        value['edition'] = edition\n",
    "        value['article'] = article\n",
    "        value['class'] = None\n",
    "        segments_ed1_list.append(value)\n",
    "\n",
    "segments_ed1_dataset = Dataset.from_list(segments_ed1_list)\n",
    "\n",
    "segments_ed1_encoded = segments_ed1_dataset.map(tokenize, batched=True, batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eca6de25e7248b08df9f62eee048819",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1000 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "edition = 2\n",
    "segments_ed2 = await load_segments(edition, range(1, 1001), get_all=False)\n",
    "\n",
    "segments_ed2_list = []\n",
    "\n",
    "for article, value_list in segments_ed2.items():\n",
    "    for value in value_list:\n",
    "        value['edition'] = edition\n",
    "        value['article'] = article\n",
    "        value['class'] = None\n",
    "        segments_ed2_list.append(value)\n",
    "\n",
    "segments_ed2_dataset = Dataset.from_list(segments_ed2_list)\n",
    "\n",
    "segments_ed2_encoded = segments_ed2_dataset.map(tokenize, batched=True, batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "043597e29f644bec9bf54ac894e05b60",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds_output_ed1 = trainer.predict(segments_ed1_encoded.remove_columns('label'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14129cf56be94c058e1c0676eeb372a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/125 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "preds_output_ed2 = trainer.predict(segments_ed2_encoded.remove_columns('label'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Column test not in the dataset. Current columns in the dataset: ['head', 'raw_text', 'text', 'label', 'qid', 'latitude', 'longitude', 'cross_refs', 'edition', 'article', 'class', 'input_ids', 'token_type_ids', 'attention_mask']\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[43], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m np\u001b[38;5;241m.\u001b[39marray(\u001b[43msegments_ed2_encoded\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\datasets\\arrow_dataset.py:2762\u001b[0m, in \u001b[0;36mDataset.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   2760\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):  \u001b[38;5;66;03m# noqa: F811\u001b[39;00m\n\u001b[0;32m   2761\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Can be used to index columns (by string names) or rows (by integer index or iterable of indices or bools).\"\"\"\u001b[39;00m\n\u001b[1;32m-> 2762\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\datasets\\arrow_dataset.py:2746\u001b[0m, in \u001b[0;36mDataset._getitem\u001b[1;34m(self, key, **kwargs)\u001b[0m\n\u001b[0;32m   2744\u001b[0m format_kwargs \u001b[38;5;241m=\u001b[39m format_kwargs \u001b[38;5;28;01mif\u001b[39;00m format_kwargs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[0;32m   2745\u001b[0m formatter \u001b[38;5;241m=\u001b[39m get_formatter(format_type, features\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info\u001b[38;5;241m.\u001b[39mfeatures, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mformat_kwargs)\n\u001b[1;32m-> 2746\u001b[0m pa_subtable \u001b[38;5;241m=\u001b[39m \u001b[43mquery_table\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_data\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindices\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_indices\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2747\u001b[0m formatted_output \u001b[38;5;241m=\u001b[39m format_table(\n\u001b[0;32m   2748\u001b[0m     pa_subtable, key, formatter\u001b[38;5;241m=\u001b[39mformatter, format_columns\u001b[38;5;241m=\u001b[39mformat_columns, output_all_columns\u001b[38;5;241m=\u001b[39moutput_all_columns\n\u001b[0;32m   2749\u001b[0m )\n\u001b[0;32m   2750\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m formatted_output\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\datasets\\formatting\\formatting.py:590\u001b[0m, in \u001b[0;36mquery_table\u001b[1;34m(table, key, indices)\u001b[0m\n\u001b[0;32m    588\u001b[0m         _raise_bad_key_type(key)\n\u001b[0;32m    589\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m--> 590\u001b[0m     \u001b[43m_check_valid_column_key\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumn_names\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    591\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    592\u001b[0m     size \u001b[38;5;241m=\u001b[39m indices\u001b[38;5;241m.\u001b[39mnum_rows \u001b[38;5;28;01mif\u001b[39;00m indices \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m table\u001b[38;5;241m.\u001b[39mnum_rows\n",
      "File \u001b[1;32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\datasets\\formatting\\formatting.py:527\u001b[0m, in \u001b[0;36m_check_valid_column_key\u001b[1;34m(key, columns)\u001b[0m\n\u001b[0;32m    525\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_check_valid_column_key\u001b[39m(key: \u001b[38;5;28mstr\u001b[39m, columns: List[\u001b[38;5;28mstr\u001b[39m]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    526\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m columns:\n\u001b[1;32m--> 527\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mColumn \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in the dataset. Current columns in the dataset: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcolumns\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"Column test not in the dataset. Current columns in the dataset: ['head', 'raw_text', 'text', 'label', 'qid', 'latitude', 'longitude', 'cross_refs', 'edition', 'article', 'class', 'input_ids', 'token_type_ids', 'attention_mask']\""
     ]
    }
   ],
   "source": [
    "\n",
    "np.array(segments_ed2_encoded[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjoAAAIjCAYAAAAKkbGTAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABVcElEQVR4nO3dd1yV5f/H8fcBWTIFB7gAxYHb3Cu0LErLHC3TglyllaM0tVxkaUNNrdzfRM3Vt9Svo+FIrdRKy1WhuTVHKgaIAxnX7w9/njyCCQmCd6/n43Eedq77uu/7cx3u4H2u+77PsRljjAAAACzIKb8LAAAAyCsEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQDZ0rx5czVv3tz+/ODBg7LZbIqNjb2ldURHRyskJOSW7jMnkpOT1a1bNwUGBspms6lv3765vo+QkBBFR0fn+nZvdwX92ED+IOgAuSQ2NlY2m03u7u46evRopuXNmzdXtWrV8qEy3EqjRo1SbGysevbsqTlz5ujJJ5/M75JuO+fPn9eIESO0bt26/C4FFlAovwsArCYlJUVvvvmm3nvvvfwuJU8FBwfrwoULcnFxye9SCpSvvvpKDRs21PDhw/NsH7t375aTk3Xfp54/f14xMTGS5DCLeCPTp09XRkZGHlWF25V1/08B8kmtWrU0ffp0HTt2LM/2YYzRhQsX8mz72XFl9srZ2Tlf6yhoTp48KT8/vzzdh5ubGwHzKufOnZMkubi4yM3NLZ+rQUFD0AFy2SuvvKL09HS9+eabN+yblpamkSNHqnz58nJzc1NISIheeeUVpaSkOPQLCQnRAw88oC+//FJ169aVh4eHpk6dqnXr1slms+njjz9WTEyMSpUqJW9vbz388MNKTExUSkqK+vbtq+LFi8vLy0tPP/10pm3PnDlTd911l4oXLy43NzdVqVJFkydPvmHt116jc6WWrB7XXjfx+eefq1mzZvL09JS3t7dat26tX375JdM+lixZomrVqsnd3V3VqlXT4sWLb1jXtfuJiIiQt7e3fHx8VK9ePc2bN8+hz3//+1/VqVNHHh4eKlq0qDp37pzp1GN0dLS8vLx09OhRtW3bVl5eXipWrJj69++v9PR0h/EfOHBAK1assI/94MGD9tOaBw8edNjulXWuPkWzZ88edejQQYGBgXJ3d1fp0qX1+OOPKzEx0d4nq2t09u/fr0ceeUT+/v4qXLiwGjZsqBUrVmS5v48//lhvvPGGSpcuLXd3d919993au3fvDV/PESNGyGaz6bffflPnzp3l6+urYsWKaejQoTLG6MiRI3rooYfk4+OjwMBAjR071mH9S5cuadiwYapTp458fX3l6empZs2aae3atfY+Bw8eVLFixSRJMTEx9tdxxIgRDj+Lffv2qVWrVvL29lanTp3sy64+1oYPHy4nJyetWbPGoY4ePXrI1dVV27dvv+GYcfvj1BWQy0JDQ/XUU09p+vTpGjRokEqWLHndvt26ddOsWbP08MMP66WXXtL333+v0aNHKy4uLtMf9d27d6tjx4565pln1L17d1WqVMm+bPTo0fLw8NCgQYO0d+9evffee3JxcZGTk5P+/PNPjRgxQt99951iY2MVGhqqYcOG2dedPHmyqlatqjZt2qhQoUJatmyZevXqpYyMDD333HPZHnd4eLjmzJnj0JaQkKAXX3xRxYsXt7fNmTNHUVFRioyM1FtvvaXz589r8uTJatq0qbZu3Wr/Q7Vy5Up16NBBVapU0ejRoxUfH6+nn35apUuXzlY9sbGx6tKli6pWrarBgwfLz89PW7du1RdffKEnnnjC3ufpp59WvXr1NHr0aP3xxx+aMGGCNmzYoK1btzrMzKSnpysyMlINGjTQmDFjtHr1ao0dO1bly5dXz5497ePv16+fSpcurZdeekmS7H+0s+PSpUuKjIxUSkqKXnjhBQUGBuro0aNavny5EhIS5Ovrm+V6f/zxhxo3bqzz58+rd+/eCggI0KxZs9SmTRt98sknateunUP/N998U05OTurfv78SExP19ttvq1OnTvr++++zVedjjz2m8PBwvfnmm1qxYoVef/11+fv7a+rUqbrrrrv01ltvae7cuerfv7/q1aunO++8U5KUlJSkGTNmqGPHjurevbvOnj2r//znP4qMjNQPP/ygWrVqqVixYpo8ebJ69uypdu3aqX379pKkGjVq2PeflpamyMhINW3aVGPGjFHhwoWzrHPIkCFatmyZunbtqp07d8rb21tffvmlpk+frpEjR6pmzZrZGi9ucwZArpg5c6aRZDZv3mz27dtnChUqZHr37m1fHhERYapWrWp/vm3bNiPJdOvWzWE7/fv3N5LMV199ZW8LDg42kswXX3zh0Hft2rVGkqlWrZq5dOmSvb1jx47GZrOZ+++/36F/o0aNTHBwsEPb+fPnM40lMjLSlCtXzqEtIiLCRERE2J8fOHDASDIzZ87M8vXIyMgwDzzwgPHy8jK//PKLMcaYs2fPGj8/P9O9e3eHvidOnDC+vr4O7bVq1TJBQUEmISHB3rZy5UojKdMYrpWQkGC8vb1NgwYNzIULFzLVZYwxly5dMsWLFzfVqlVz6LN8+XIjyQwbNszeFhUVZSSZ1157zWFbtWvXNnXq1HFoCw4ONq1bt3Zou3JsHDhwwKH9ys9v7dq1xhhjtm7daiSZ//73v387vuDgYBMVFWV/3rdvXyPJfPPNN/a2s2fPmtDQUBMSEmLS09Md9hceHm5SUlLsfSdMmGAkmZ07d/7tfocPH24kmR49etjb0tLSTOnSpY3NZjNvvvmmvf3PP/80Hh4eDnWmpaU57PdKvxIlSpguXbrY206dOmUkmeHDh2eq4crPYtCgQVkuu/bY2Llzp3F1dTXdunUzf/75pylVqpSpW7euSU1N/duxwjo4dQXkgXLlyunJJ5/UtGnTdPz48Sz7fPbZZ5KkF1980aH9ykzAtacdQkNDFRkZmeW2nnrqKYdrNho0aCBjjLp06eLQr0GDBjpy5IjS0tLsbR4eHvb/TkxM1OnTpxUREaH9+/c7nC7JqZEjR2r58uWKjY1VlSpVJEmrVq1SQkKCOnbsqNOnT9sfzs7OatCggf0UxvHjx7Vt2zZFRUU5zGLcc8899m39nVWrVuns2bMaNGiQ3N3dHZbZbDZJ0pYtW3Ty5En16tXLoU/r1q1VuXLlTK+/JD377LMOz5s1a6b9+/dn8xW5sStj/fLLL3X+/Plsr/fZZ5+pfv36atq0qb3Ny8tLPXr00MGDB/Xrr7869H/66afl6upqf96sWTNJyvZYunXrZv9vZ2dn1a1bV8YYde3a1d7u5+enSpUqOWzT2dnZvt+MjAydOXNGaWlpqlu3rn766adsj1eSevbsma1+1apVU0xMjGbMmKHIyEidPn1as2bNUqFCnND4tyDoAHlkyJAhSktLu+61OocOHZKTk5PCwsIc2gMDA+Xn56dDhw45tIeGhl53X2XLlnV4fuUPZpkyZTK1Z2RkOASYDRs2qGXLlvL09JSfn5+KFSumV155RZL+cdD54osvFBMTo8GDB6tDhw729j179kiS7rrrLhUrVszhsXLlSp08eVKS7GOvUKFCpm1ffcruevbt2ydJf3s7/5V9ZLW9ypUrZ3r93d3dM52GKlKkiP78888b1pNdoaGhevHFFzVjxgwVLVpUkZGR+uCDD274czh06FCW4wgPD7cvv9q1x0uRIkUkKdtjyep4c3d3V9GiRTO1X7vNWbNmqUaNGnJ3d1dAQICKFSumFStW5OhYK1SoULZPYUrSgAEDVLNmTf3www8aPnx4tsIyrINIC+SRcuXKqXPnzpo2bZoGDRp03X5XZhhu5OqZl2td786n67UbYyRdDgR33323KleurHHjxqlMmTJydXXVZ599pnffffcf3ap74MABderUSffcc49ef/11h2VXtjdnzhwFBgZmWrcgv8u+mbvLrvczvnIh89XGjh2r6Oho/e9//9PKlSvVu3dvjR49Wt99912O/rj/nRsdF/9k/exs86OPPlJ0dLTatm2rAQMGqHjx4nJ2dtbo0aPt4TQ73NzccnR7/f79++0he+fOndleD9ZQcH+rABYwZMgQffTRR3rrrbcyLQsODlZGRob27Nljf+ctXb6wNCEhQcHBwXle37Jly5SSkqKlS5c6vEu/+i6YnLhw4YLat28vPz8/zZ8/P9Mfo/Lly0uSihcvrpYtW153O1fGfuWP09V27959wzqu7Ofnn3/ONGN27T52796tu+66K9M+cvP1vzJjkpCQ4NB+7UzLFdWrV1f16tU1ZMgQbdy4UU2aNNGUKVMyBccrgoODs3xddu3aZV9eEHzyyScqV66cFi1a5BD+rv3MoeyG/+zIyMhQdHS0fHx81LdvX40aNUoPP/yw/SJnWB+nroA8VL58eXXu3FlTp07ViRMnHJa1atVKkjR+/HiH9nHjxkm6fK1IXrvyLvzqd92JiYmaOXPmP9res88+q99++02LFy+2/3G/WmRkpHx8fDRq1CilpqZmWn7q1ClJUlBQkGrVqqVZs2Y5nNJYtWpVputNsnLvvffK29tbo0eP1sWLFx2WXRlr3bp1Vbx4cU2ZMsXhlvvPP/9ccXFxufr6XwleX3/9tb0tPT1d06ZNc+iXlJTkcP2UdDn0ODk5ZfpYgKu1atVKP/zwgzZt2mRvO3funKZNm6aQkJACc6omq+Pt+++/d6hbkv0uqmuD4T8xbtw4bdy4UdOmTdPIkSPVuHFj9ezZU6dPn77pbeP2wIwOkMdeffVVzZkzR7t371bVqlXt7TVr1lRUVJSmTZumhIQERURE6IcfftCsWbPUtm1btWjRIs9ru/fee+Xq6qoHH3xQzzzzjJKTkzV9+nQVL178uhdRX8+KFSs0e/ZsdejQQTt27NCOHTvsy7y8vNS2bVv5+Pho8uTJevLJJ3XHHXfo8ccfV7FixXT48GGtWLFCTZo00fvvvy/p8i3zrVu3VtOmTdWlSxedOXNG7733nqpWrark5OS/rcXHx0fvvvuuunXrpnr16umJJ55QkSJFtH37dp0/f16zZs2Si4uL3nrrLT399NOKiIhQx44d7beXh4SEqF+/fjl/Qa+jatWqatiwoQYPHqwzZ87I399fCxYsyBRqvvrqKz3//PN65JFHVLFiRaWlpWnOnDlydnZ2uNbpWoMGDdL8+fN1//33q3fv3vL399esWbN04MABffrppwXmU5QfeOABLVq0SO3atVPr1q114MABTZkyRVWqVHH4mXp4eKhKlSpauHChKlasKH9/f1WrVi3HX6ESFxenoUOHKjo6Wg8++KCkyx8pUKtWLfXq1Usff/xxro4PBVT+3fAFWMvVt5df68otsVffXm6MMampqSYmJsaEhoYaFxcXU6ZMGTN48GBz8eJFh35Z3bJszF+3C197O/L1arlye/CpU6fsbUuXLjU1atQw7u7uJiQkxLz11lvmww8/zHQ79I1uL7+yz6we197yu3btWhMZGWl8fX2Nu7u7KV++vImOjjZbtmxx6Pfpp5+a8PBw4+bmZqpUqWIWLVqU5S3E17N06VLTuHFj4+HhYXx8fEz9+vXN/PnzHfosXLjQ1K5d27i5uRl/f3/TqVMn8/vvvzv0iYqKMp6enpm2f+X1vNr1flb79u0zLVu2NG5ubqZEiRLmlVdeMatWrXK4vXz//v2mS5cupnz58sbd3d34+/ubFi1amNWrV2fax9W3bV/Z/sMPP2z8/PyMu7u7qV+/vlm+fLlDn+sdLzf6qIBrx3v18WPM9V+faz9SISMjw4waNcoEBwcbNzc3U7t2bbN8+fIsf6YbN240derUMa6urg63ml9vX1eWXdlOWlqaqVevnildurTDRxQY89ft9AsXLvzb8cIabMZk8+ozAACA20zBmM8EAADIAwQdAABgWQQdAABgWQQdAABgWQQdAABgWQQdAABgWXxgYAGQkZGhY8eOydvbO1c/+hwAACsyxujs2bMqWbLkDT8Qk6BTABw7dizTt0wDAIC/d+TIkRt+2S1BpwDw9vaWJLlWiZLN2TWfq4GVHV43Jr9LAICbdjYpSWGhZex/P/8OQacAuHK6yubsStBBnvLx8cnvEgAg12Tncg8uRgYAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0AEAAJZF0EG+a1y7vOaPe0a/fvaG/tz8vlpF1LjhOk3uqKB1cwbqxIZ39eOi4er4QINMfbo9cqe2/y9Gx799V6tm9tcdVYLzonzcZqZ/vF412gxTYJO+ahn9jn785eDf9l+y+ifVf3ikApv0VePH39DKDb84LDfGaNSU5ap83ysKatpPbXu9p32HT+bhCHA74DgrOAg6yHeFPdz0829HNeDthdnqX7ZkgBaOf1bf/Pib7uz0pqbMX6uJrz6huxqG2/u0u+cOvd63nd6a8bmaP/mWft5zVJ++95yKFvHKq2HgNrBo5Y8aMn6xBna7X+vmDFS1CqXU4YUPdOrM2Sz7f799v7oNiVXnhxpp/UeD1Dqipjr3n6Zf9x6z95kwe7WmLlyvcYMf16qZ/VXYw1UdXvhAF1NSb9WwUMBwnBUst1XQiY6Ols1mk81mk6urq8LCwvTaa68pLS0tv0vDTVi98Ve9MWW5Vqzbka3+Xdo31eFj8Ro6frF+O/iHpv/3ay39apt6PtHC3qfXE3dp9pKNmrfsO+0+cEIvjl6g8xcvqXObRnk1DNwGJs37Sk+1baxObRqpcrkgjRv8uAq7u+qjpZuy7D91wTrd3ShcvZ9sqUqhgXq15wOqWbmMpv93vaTL77KnzF+r/l0i1SqihqpVKKXJMU/pxOlErVi//VYODQUIx1nBclsFHUm67777dPz4ce3Zs0cvvfSSRowYoXfeeSfH20lPT1dGRkYeVIi8Vq96qNb9sNuhbc13capfPVSS5FLIWbUql3HoY4zR+h92q97/98G/z6XUNG3bdUTN61eytzk5OSmifiVt3nkgy3V+2HlAzetVdmi7q2G4Nu88KEk6dDRef8QnqXn9v/r4enmoTtUQbd5xMNfHgIKP46zgue2CjpubmwIDAxUcHKyePXuqZcuWWrp0qVJSUtS/f3+VKlVKnp6eatCggdatW2dfLzY2Vn5+flq6dKmqVKkiNzc3HT58WOvWrVP9+vXl6ekpPz8/NWnSRIcOHbKvN3nyZJUvX16urq6qVKmS5syZ41CPzWbTjBkz1K5dOxUuXFgVKlTQ0qVLb9XL8a9UPMAn0xTwqfgk+Xh5yN3NRQF+XipUyDlznzNJKh7gcytLRQESn5Cs9PQMFfP3dmgv5u+jk/FJWa5zMj5JxQKu7e9t7//H//97bZ/iAd7X3SasjeOs4Lntgs61PDw8dOnSJT3//PPatGmTFixYoB07duiRRx7Rfffdpz179tj7nj9/Xm+99ZZmzJihX375Rf7+/mrbtq0iIiK0Y8cObdq0ST169JDNZpMkLV68WH369NFLL72kn3/+Wc8884yefvpprV271qGGmJgYPfroo9qxY4datWqlTp066cyZM9etOSUlRUlJSQ4PAACQ+27boGOM0erVq/Xll1+qRo0amjlzpv773/+qWbNmKl++vPr376+mTZtq5syZ9nVSU1M1adIkNW7cWJUqVVJaWpoSExP1wAMPqHz58goPD1dUVJTKli0rSRozZoyio6PVq1cvVaxYUS+++KLat2+vMWPGONQSHR2tjh07KiwsTKNGjVJycrJ++OGH69Y+evRo+fr62h9lypTJmxfJok7GJ2V+txTgo6TkC7qYkqr4hGSlpaXn6B0VrC/Az0vOzk45mukrHuCjU/HX9j9r71/i//+9ts/J+LPMHv5LcZwVPLdd0Fm+fLm8vLzk7u6u+++/X4899pgefvhhpaenq2LFivLy8rI/1q9fr3379tnXdXV1VY0af9267O/vr+joaEVGRurBBx/UhAkTdPz4cfvyuLg4NWnSxGH/TZo0UVxcnEPb1dv09PSUj4+PTp68/m1/gwcPVmJiov1x5MiRf/x6/Btt3nlAEfUqObS1qF9ZP/z/+e/UtHRt23XEoY/NZtOd9Spe9xw5rM/VpZBqVS6j9Zv/unYrIyNDX2/+7brXbtWvHurQX5LWfr9L9aqHSJKCSwWoRICPQ5+k5Av68ZeDqlcjJNfHgIKP46zgue2CTosWLbRt2zbt2bNHFy5c0KxZs5ScnCxnZ2f9+OOP2rZtm/0RFxenCRMm2Nf18PCwn5a6YubMmdq0aZMaN26shQsXqmLFivruu+9yVJOLi4vDc5vN9rcXOru5ucnHx8fh8W/m6eGqahVLqVrFUpKk4JIBqlaxlEqXKCJJGvZcG00e8aS9/4eLvlVwqQDFvPCQKgSXUNeHm6lty9qaPO+vU4pX7np4vHUDVQwpoXGDHpOnh5vmLsvZzxbWcuVuvPnL//9uvDcX6tyFFHV6sKEk6dnhsxXz/v/s/Z95vLnWbPpV73+0Rr8dPKE3p63QtrjD6v5IhKTL/68/27GFxnz4hT5bv0O/7D2qniPmKLCor1pH1MyXMSL/cZwVLIXyu4Cc8vT0VFhYmENb7dq1lZ6erpMnT6pZs2Y53mbt2rVVu3ZtDR48WI0aNdK8efPUsGFDhYeHa8OGDYqKirL33bBhg6pUqXLT48BfaoUHa/nUPvbno17sIEmat/w7PRfzkUoU9VHpQH/78sPH4vVY3yka9WJ7PfN4cx07maDeb8zTV9/9NdO2eNVPKurnpVeeaa3iAd7a+dtRPdz7+p9jgX+H9vfW0emEZI2aukIn48+qesVS+mTic/bp/99PnJHTVW+GGtQsp+mvR+uNycs1ctIylStTTB+N6aEqYSXtffo81VLnL6So36j5Sky+oIY1y+uTib3k7uaSaf/4d+A4K1hsxhiT30VkV3R0tBISErRkyZJMyzp37qwNGzZo7Nixql27tk6dOqU1a9aoRo0aat26tWJjY9W3b18lJCTY1zlw4ICmTZumNm3aqGTJktq9e7eeeOIJjRw5Uj179tSSJUv06KOPasKECWrZsqWWLVuml19+WatXr1bz5s0lXU7aixcvVtu2be3b9fPz0/jx4xUdHZ2tcSUlJcnX11du1bvL5uz6z18g4Ab+3Px+fpcAADctKSlJJQJ8lZiYeMOzIrfdjM71zJw5U6+//rpeeuklHT16VEWLFlXDhg31wAMPXHedwoULa9euXZo1a5bi4+MVFBSk5557Ts8884wkqW3btpowYYLGjBmjPn36KDQ0VDNnzrSHHAAAULDdVjM6VsWMDm4VZnQAWEFOZnRuu4uRAQAAsougAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALIugAwAALKtQfheAvxxeN0Y+Pj75XQYsLHzAivwuAf8Cc3s1zu8SYHHnkpOy3ZcZHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFkEHQAAYFmFstNp6dKl2d5gmzZt/nExAAAAuSlbQadt27bZ2pjNZlN6evrN1AMAAJBrshV0MjIy8roOAACAXHdT1+hcvHgxt+oAAADIdTkOOunp6Ro5cqRKlSolLy8v7d+/X5I0dOhQ/ec//8n1AgEAAP6pHAedN954Q7GxsXr77bfl6upqb69WrZpmzJiRq8UBAADcjBwHndmzZ2vatGnq1KmTnJ2d7e01a9bUrl27crU4AACAm5HjoHP06FGFhYVlas/IyFBqamquFAUAAJAbchx0qlSpom+++SZT+yeffKLatWvnSlEAAAC5IVu3l19t2LBhioqK0tGjR5WRkaFFixZp9+7dmj17tpYvX54XNQIAAPwjOZ7Reeihh7Rs2TKtXr1anp6eGjZsmOLi4rRs2TLdc889eVEjAADAP5LjGR1JatasmVatWpXbtQAAAOSqfxR0JGnLli2Ki4uTdPm6nTp16uRaUQAAALkhx0Hn999/V8eOHbVhwwb5+flJkhISEtS4cWMtWLBApUuXzu0aAQAA/pEcX6PTrVs3paamKi4uTmfOnNGZM2cUFxenjIwMdevWLS9qBAAA+EdyPKOzfv16bdy4UZUqVbK3VapUSe+9956aNWuWq8UBAADcjBzP6JQpUybLDwZMT09XyZIlc6UoAACA3JDjoPPOO+/ohRde0JYtW+xtW7ZsUZ8+fTRmzJhcLQ4AAOBmZOvUVZEiRWSz2ezPz507pwYNGqhQocurp6WlqVChQurSpYvatm2bJ4UCAADkVLaCzvjx4/O4DAAAgNyXraATFRWV13UAAADkun/8gYGSdPHiRV26dMmhzcfH56YKAgAAyC05vhj53Llzev7551W8eHF5enqqSJEiDg8AAICCIsdB5+WXX9ZXX32lyZMny83NTTNmzFBMTIxKliyp2bNn50WNAAAA/0iOT10tW7ZMs2fPVvPmzfX000+rWbNmCgsLU3BwsObOnatOnTrlRZ0AAAA5luMZnTNnzqhcuXKSLl+Pc+bMGUlS06ZN9fXXX+dudQAAADchxzM65cqV04EDB1S2bFlVrlxZH3/8serXr69ly5bZv+QT+Cemf7xe7320Rifjk1StQim9NeAR1akact3+S1b/pFFTVujw8XiVK1NMI15oq3ubVLUvN8Zo9NQVmr1koxKTL6hBjXIaO+gxlS9b/BaMBgXVE42D1SWinIp6u2nX8SS9seQX7TySmGXfWc82VP3yAZna18ed1LMfbpYkjXqshtrVLeOw/JvdJ9VjxubcLx63jSVffK+Pl32rMwnJKh8cqBe6tFblsKy/9HrF6i1a+fU2HTzyhySpYrmS6trxHof+b32wSCvXb3VYr17NML35KndF30iOg87TTz+t7du3KyIiQoMGDdKDDz6o999/X6mpqRo3blxe1HhL2Ww2LV68mA8+vMUWrfxRQ8Yv1rhBj6lOtRBNmb9WHV74QJs/GaZi/t6Z+n+/fb+6DYnVsOfaKLJpNX3yxRZ17j9N6+YMVJWwy19FMmH2ak1duF6TRzypsiUDNGrKcnV44QN99/EQubu53OohogC4v2aQBj4YrhGf/qwdhxP0VLNQTe/WQK3eXqcz5y5l6t971o9yKfTXxLdfYRct7tdMX+w47tDv610n9erHO+zPL6Wl590gUOCt3bhTU2Z/rr7d26hyhdJatGKTBr4xS7Hj+6iIr1em/tt/PaC7mlRX1Uqt5epSSAv+941efn2W/jPuBRXz/+tO5nq1KujlXu3sz10K3dSN0/8aOT511a9fP/Xu3VuS1LJlS+3atUvz5s3T1q1b1adPnxxtKzo6Ot8CxYgRI1SrVq1M7cePH9f9999/6wv6l5s07ys91baxOrVppMrlgjRu8OMq7O6qj5ZuyrL/1AXrdHejcPV+sqUqhQbq1Z4PqGblMpr+3/WSLs/mTJm/Vv27RKpVRA1Vq1BKk2Oe0onTiVqxfvutHBoKkKg7Q/Xf749o8Zbfte9kskYs2qmLqelqX79Mlv0TL6Tq9NkU+6NxhaK6mJquL7c7Bp1LaRkO/ZIupN2K4aCA+mT5RrW6u67ua3GHQkoXV9/uD8rN1UVfrP0py/6v9H5ED0U2UFhIkMqWKqaXnm0rY4y27tzn0M+lkLP8/bztD28vj1sxnNtejoPOtYKDg9W+fXvVqFEjN+rJd4GBgXJzc8vvMv5VLqWmaduuI2pev5K9zcnJSRH1K2nzzgNZrvPDzgNqXq+yQ9tdDcO1eedBSdKho/H6Iz5Jzev/1cfXy0N1qoZo846DuT4GFHwuzjZVLeWrTXtO29uMkTbtOa1awX7Z2kaH+mX02bbjupDqOGNTv3yAvh3eUp8NiNDw9tXkV5gZw3+r1LQ0/bb/mO6oXs7e5uTkpDuql9evvx3J1jZSUlKVlpYub6/CDu3bfz2oDt3eVFSf8Ro/fakSz57P1dqtKlvzXhMnTsz2Bq/M9tys9evXa8CAAdq+fbv8/f0VFRWl119/3f79WhkZGRozZoymTZumI0eOqESJEnrmmWf06quvSpIGDhyoxYsX6/fff1dgYKA6deqkYcOGycXFRbGxsYqJiZEk+3d4zZw5U9HR0ZlOXe3cuVN9+vTRpk2bVLhwYXXo0EHjxo2Tl9fl6cfo6GglJCSoadOmGjt2rC5duqTHH39c48ePl4sLv+yyIz4hWenpGZlOURXz99Geg39kuc7J+CQVC7i2v7dOxidJkv74/3+v7VM84K8++Hfx83RVIWcnxSenOLTHJ6cotLjnDdevXsZXFYN8NOS/Oxzav911Sqt2ntDvZy6obEBh9b2/kqZ2ra+O729QhsnVIeA2kJh0XhkZGSri53iKqoifl44cO32dtRxNn7tSAf7eqnNVWKpXK0zNGoQrsHgRHTtxRv+Zv1qDR83We2/0kLPTTc9ZWFq2gs67776brY3ZbLZcCTpHjx5Vq1atFB0drdmzZ2vXrl3q3r273N3dNWLECEnS4MGDNX36dL377rtq2rSpjh8/rl27dtm34e3trdjYWJUsWVI7d+5U9+7d5e3trZdfflmPPfaYfv75Z33xxRdavXq1JMnX1zdTHefOnVNkZKQaNWqkzZs36+TJk+rWrZuef/55xcbG2vutXbtWQUFBWrt2rfbu3avHHntMtWrVUvfu3bMcX0pKilJS/vplm5TEH16goOtQv4x2H0/KdOHyZ1edxtpz4qx2H0/SqsF3qX75AH23N/5Wl4nb3PwlX2vthp0aO6KLXF3/erN8V5O/zpqUKxuocsGBevKFd7X9lwO6o3r5/Cj1tpGtoHPgQNanD/LKpEmTVKZMGb3//vuy2WyqXLmyjh07poEDB2rYsGE6d+6cJkyYoPfff9/+PVzly5dX06ZN7dsYMmSI/b9DQkLUv39/LViwQC+//LI8PDzk5eWlQoUKKTAw8Lp1zJs3TxcvXtTs2bPl6Xn5Hd/777+vBx98UG+99ZZKlCgh6fK3u7///vtydnZW5cqV1bp1a61Zs+a6QWf06NH2GSVIAX5ecnZ20qkzZx3aT51JUvGArL9SpHiAj07FX9v/rL1/if//91T8WQUW/SvEnow/q+oVs77zAdaWcO6S0tIzFODleGo6wMtNp8+mXGetyzxcnNWqZkm9t/K3G+7n9zMXdCY5RWWLehJ0/oV8fQrLyclJfyYkO7T/mZAsf7/MFyJf7eOl32r+km/0ztBolQ++/t8mSSpZwl++3oV19MQZgs4NFMj5rri4ODVq1Mh+WkmSmjRpouTkZP3++++Ki4tTSkqK7r777utuY+HChWrSpIkCAwPl5eWlIUOG6PDhwzmuo2bNmvaQc6WOjIwM7d69295WtWpVOTs7258HBQXp5MmT193u4MGDlZiYaH8cOZK987ZW5epSSLUql9H6zX+9phkZGfp682+qVz00y3XqVw916C9Ja7/fpXrVQyRJwaUCVCLAx6FPUvIF/fjLQdWrEZLrY0DBl5pu9MvRRDUMK2pvs9mkhmEB2nYo4W/XjawZJNdCTlr209Eb7qeEr7v8CrvqVNLFmy0ZtyGXQoVUsVxJbf15v70tIyNDW3/eryoVs77oXZIW/O8bffTpOr35ylOqVL7UDfdzKj5RSckXFFDk78MTCmjQuREPj7+/0nzTpk3q1KmTWrVqpeXLl2vr1q169dVXM30BaW659locm82mjIyM6/Z3c3OTj4+Pw+PfrtcTd2n2ko2av/w77T5wQi++uVDnLqSo04MNJUnPDp+tmPf/Z+//zOPNtWbTr3r/ozX67eAJvTlthbbFHVb3RyIkXf4ZPNuxhcZ8+IU+W79Dv+w9qp4j5iiwqK9aR9TMlzEi/836+oAeaVBGD9UppXLFvTS8fTV5uBbS4s2X32y8+XhN9bu/Uqb1OtQrozW//KGE86kO7YVdndW/dWXVLOunkkU81DAsQB9E19Xh+HP6dnf2rseA9Tz8QGOtWPOjvly3VYd+P6nxM5bpYsolRTa/Q5L05vufaMa8lfb+85d8rdiFa9S/ZzsFFvfTmYSzOpNwVhcuXp5pvHAxRVPnfKFffzuiEyf/1E8792no2/NUMtBfdWtWyJcx3k4K5E344eHh+vTTT2WMsc/qbNiwQd7e3ipdurSKFy8uDw8PrVmzRt26dcu0/saNGxUcHGy/MFmSDh065NDH1dVV6el//1kX4eHhio2N1blz5+yzOhs2bJCTk5MqVcr8yxD/XPt76+h0QrJGTV3x/6eXSumTic/ZT0X9fuKMnK6a4WtQs5ymvx6tNyYv18hJy1SuTDF9NKaH/TN0JKnPUy11/kKK+o2ar8TkC2pYs7w+mdiLz9D5F/t8+3EV8XRV78iKKurtprhjSeox4wfFJ19+ExTk56EM43gFcUgxT9Ut56+u077PtL30DKNKQT5qW7e0vN1ddCrpojb8dloTv9yt1PTrv9mBtbVoXF2JSecU+/Ea/ZmQrPIhQXrzlafsp65Onk6UzfbXPMOyVZuVmpaumHELHLbz1MMtFPXoXXJyctL+w39o5fptSj53UQH+3qpbI0zRj90tV5cC+We8QLEZY/LtvoDo6GgdOnQo08XORYoUUZUqVfT000/r+eef1+7du9WtWzc999xz9ouRY2JiNGHCBI0fP15NmjTRqVOn9Msvv6hr165aunSpOnTooDlz5qhevXpasWKFYmJilJ6eroSEBEmXr7/p0aOHvv32W5UuXVre3t5yc3NzuOvq/PnzCgsLU+PGjTVixAidOnVK3bp1U7NmzewXI1+562rJkiX2+vv27att27Zp3bp12XodkpKS5Ovrqz/iE5ndQZ4KH7Aiv0vAv8DcXo3zuwRY3LnkJN17R4gSE2/8dzPfo+C6detUu3Zth7auXbvqs88+04ABA1SzZk35+/ura9euDhcYDx06VIUKFdKwYcN07NgxBQUF6dlnn5UktWnTRv369dPzzz+vlJQUtW7dWkOHDrWHJEnq0KGDFi1apBYtWighIcF+e/nVChcurC+//FJ9+vRRvXr1HG4vBwAABd8/mtH55ptvNHXqVO3bt0+ffPKJSpUqpTlz5ig0NNThzidkDzM6uFWY0cGtwIwO8lpOZnRyfDHyp59+qsjISHl4eGjr1q32z4NJTEzUqFGj/lnFAAAAeSDHQef111/XlClTNH36dIe7jZo0aaKffsr6ezwAAADyQ46Dzu7du3XnnXdmavf19bVf6AsAAFAQ5DjoBAYGau/evZnav/32W5UrVy6LNQAAAPJHjoNO9+7d1adPH33//fey2Ww6duyY5s6dq/79+6tnz555USMAAMA/kuPbywcNGqSMjAzdfffdOn/+vO688065ubmpf//+euGFF/KiRgAAgH8kx0HHZrPp1Vdf1YABA7R3714lJyerSpUq8vLi+zYAAEDB8o8/MNDV1VVVqlTJzVoAAAByVY6DTosWLRy+VfxaX3311U0VBAAAkFtyHHRq1arl8Dw1NVXbtm3Tzz//rKioqNyqCwAA4KblOOhc+wWcV4wYMULJyck3XRAAAEBuyfHt5dfTuXNnffjhh7m1OQAAgJuWa0Fn06ZNcnd3z63NAQAA3LQcn7pq3769w3NjjI4fP64tW7Zo6NChuVYYAADAzcpx0PH19XV47uTkpEqVKum1117Tvffem2uFAQAA3KwcBZ309HQ9/fTTql69uooUKZJXNQEAAOSKHF2j4+zsrHvvvZdvKQcAALeFHF+MXK1aNe3fvz8vagEAAMhVOQ46r7/+uvr376/ly5fr+PHjSkpKcngAAAAUFNm+Rue1117TSy+9pFatWkmS2rRp4/BVEMYY2Ww2paen536VAAAA/0C2g05MTIyeffZZrV27Ni/rAQAAyDXZDjrGGElSREREnhUDAACQm3J0jc7ffWs5AABAQZOjz9GpWLHiDcPOmTNnbqogAACA3JKjoBMTE5Ppk5EBAAAKqhwFnccff1zFixfPq1oAAAByVbav0eH6HAAAcLvJdtC5ctcVAADA7SLbp64yMjLysg4AAIBcl+OvgAAAALhdEHQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlFcrvAvCXS2kZupSWkd9lwMLi3mmd3yXgX6BI05fzuwRYnElLyXZfZnQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlEXQAAIBlFcrvAoArPvzka02a+5VOnklSlbBSGvXiw7qjavB1+y9ds1VvTVuhIyfOKLR0MQ19ro1aNq5qX/7OjM+0ZNVPOnoyQa4uzqpRqYwGP/uA6lQNuQWjQUE1/eP1eu+jNToZn6RqFUrprQGP/O0xsWT1Txo1ZYUOH49XuTLFNOKFtrq3yV/HmTFGo6eu0OwlG5WYfEENapTT2EGPqXzZ4rdgNCiourVvpBc6Rqi4v7d+3ndcA9/9n36KO5Jl30LOTur35F3qeH8dBRX10d4jpzRi8mda8/1v9j7b/ztIZYP8M607Y9FGDRi3JK+GYQnM6Py/2NhY+fn55XcZ/1pLVv+k4RMX66Wu92lV7ABVrVBKj/ebpFNnzmbZf/OO/Xp2+Cw98WAjrZ71su6/s4aiB85Q3L5j9j7lyhTXqJce0bqPBmnplL4qE+Svx/pM0uk/s94mrG/Ryh81ZPxiDex2v9bNGahqFUqpwwsfXPc4+377fnUbEqvODzXS+o8GqXVETXXuP02/7v3rOJswe7WmLlyvcYMf16qZ/VXYw1UdXvhAF1NSb9WwUMC0u6umXn/+Qb01c7Wad52gn/ce16fjuqqon2eW/Yf0iFT0Qw008N3/qeGTYzVzyXeaMypK1SuUtPe5q/t7qtTmNfujbd9pkqQla3fckjHdziwXdI4cOaIuXbqoZMmScnV1VXBwsPr06aP4+Hh7n5CQEI0fPz7/ikQmU+avVec2jdXxgYaqFBqkd15+VB5urpq//Lss+0/7eL1aNAjXc53vVsWQQA16prWqVyqtDz/5xt6nQ2RdRdSvpJBSRVW5XJBe69NOZ89ddPgjhX+XSfO+0lNtG6tTm0aqXC5I4wY/rsLurvpo6aYs+09dsE53NwpX7ydbqlJooF7t+YBqVi6j6f9dL+nybM6U+WvVv0ukWkXUULUKpTQ55imdOJ2oFeu338qhoQDp9XgzzV72veZ9tkW7D57Ui+8s0vmLqer8QL0s+z8aWUfvzvlKq77bpUPHzujDJd9p1aZdev7xO+194hPO6eSZZPsjsnG49v9+Whu27r9Vw7ptWSro7N+/X3Xr1tWePXs0f/587d27V1OmTNGaNWvUqFEjnTlz5pbXlJrKu7obuZSaph27j6hZvUr2NicnJ91Zr5K2/Hwgy3V+/Pmg7qxX0aGtRYPw6/a/lJqmOUs2ysfLQ1UrlMq94nHbuJSapm27jqh5fcfjLKJ+JW3emfVx88POA2per7JD210Nw7V550FJ0qGj8fojPknN6//Vx9fLQ3WqhmjzjoO5PgYUfC6FnFWrYimt27LX3maM0fote1TvOqfi3VycdTElzaHtYkqqGtYIue4+Hr33Ds1dsTnX6rYySwWd5557Tq6urlq5cqUiIiJUtmxZ3X///Vq9erWOHj2qV199Vc2bN9ehQ4fUr18/2Ww22Ww2h218+eWXCg8Pl5eXl+677z4dP37cYfmMGTMUHh4ud3d3Va5cWZMmTbIvO3jwoGw2mxYuXKiIiAi5u7tr7ty5t2Tst7MzCeeUnp6hYv7eDu3F/L11Mj7rUwon45NUzN/nhv1XfvuzQu/qr7IRL2nqgnX6eEIvBfh55e4AcFuIT0i+znHmo5PxSVmuczI+ScUCsjouL/f/4///vbZP8QDv624T1hbg66lChZwznQ49dSZZxa85Tq746off1OvxZipXuqhsNpua162gByKqqUSAT5b9W99ZVb5e7pr32Y+5Xr8VWeZi5DNnzujLL7/UG2+8IQ8PD4dlgYGB6tSpkxYuXKg9e/aoVq1a6tGjh7p37+7Q7/z58xozZozmzJkjJycnde7cWf3797eHlblz52rYsGF6//33Vbt2bW3dulXdu3eXp6enoqKi7NsZNGiQxo4dq9q1a8vd3T1TrSkpKUpJSbE/T0riF2JeaVKngr6aNVDxicn66H+b1H3ITH0+46VMf+wAIL8MmrBUE17uoB/m9pcxRgeOndG8z7aoU+usT3V1bl1Pq7/frROE6WyxTNDZs2ePjDEKDw/Pcnl4eLj+/PNPpaeny9nZWd7e3goMDHTok5qaqilTpqh8+fKSpOeff16vvfaaffnw4cM1duxYtW/fXpIUGhqqX3/9VVOnTnUIOn379rX3ycro0aMVExPzj8dqNf5+nnJ2dsriHdDZ674DKh7go1Nnkm7Y39PDTaFliim0TDHVrRaqho+M1Lxlm9Qn6t7cHQQKvAA/r+scZ0kqfp13zsUDfHQqPqvj8nL/K++4T8WfVWBRX3ufk/FnVb1i6dwsH7eJ+MRzSktLz2Lm0Ou6M9TxCefU+ZXZcnMtJH+fwjp+Okkjet6vg8fiM/UtU8JPzetW0JOvzs6T+q3IUqeupMvnQv+pwoUL20OOJAUFBenkyZOSpHPnzmnfvn3q2rWrvLy87I/XX39d+/btc9hO3bp1/3Y/gwcPVmJiov1x5EjWtxz+W7i6FFKNSmX0zZa/bqXMyMjQN1t2q2610CzXqVMtxKG/JK3/Ydd1+9u3azJ0KTXtb/vAmlxdCqlW5TJav3m3vS0jI0Nfb/5N9apnfdzUrx7q0F+S1n6/S/Wqh0iSgksFqESAj0OfpOQL+vGXg6p3nesrYG2paena9ttRRdQJs7fZbDbdWSdMm3859LfrplxK0/HTSSrk7KQHI6rr829+zdTnidb1dOrPZK3ctCvXa7cqy8zohIWFyWazKS4uTu3atcu0PC4uTkWKFFGxYsWuuw0XFxeH5zabzR6ckpOTJUnTp09XgwYNHPo5Ozs7PPf0zPoWwivc3Nzk5ub2t33+bZ7t2EK9R36kWpXLqHbVYE1bsE7nL17S4w9cfq2fj5mjwGK+GtKrjSSpx6MRattroibP+0otG1fVktU/avuuIxoz6HFJ0rkLKRofu1KRzaqpRICvziQm68NPvtGJU4l68K7a+TZO5K9eT9ylXjFzVDu8rO6oGqLJ89fq3IUUdXqwoSTp2eGzFVTMV8Off0iS9MzjzfXAM+P1/kdrdG/Tqlq08kdtizus8a90lHT5d8SzHVtozIdfqFyZYgouFaBRU1YosKivWkfUzLdxIn9NWvCNJr36qLbu+l0/xR1Rz0ebytPDVXNXbJEkTR7ymI6fStRrU7+QJNWpUkZBRX21c+8xlSzqo4Fd7pGTk00T5q1z2K7NZlOnVnW14IsflZ6ecauHdduyTNAJCAjQPffco0mTJqlfv34O1+mcOHFCc+fO1VNPPSWbzSZXV1elp6fnaPslSpRQyZIltX//fnXq1Cm3y//Xa9vyDsX/may3Z3ymk/FJqlqhtOa/21PF//+C46N//Cknp78uHK9Xo5wmx0TpzWkrNGrKMoWWKa7Yt7opvPzlz51wdnLS3kN/6OPPftCZxGQV8fVUrfCy+t/kPqpcLihfxoj81/7eOjqdkKxRU1f8/+mlUvpk4nP2U1G/nzgjp6tuUGhQs5ymvx6tNyYv18hJy1SuTDF9NKaHqoT99fkmfZ5qqfMXUtRv1HwlJl9Qw5rl9cnEXnJ3c8m0f/w7LP5qu4r6eeqVbvequL+3du49podf+o9O/Xn5DXPpEn7KyPjr7IObq4te7R6pkJL+OnfhklZ9t0vPjlyopOSLDtttXjdMZQKL6CPutsoRm7mZcz0FzJ49e9S4cWOFh4fr9ddfV2hoqH755RcNGDBAKSkp+u677+Tv7697771XHh4emjRpktzc3FS0aFHFxsaqb9++SkhIsG9vyZIlateunX1WZ8aMGerdu7fefPNN3XfffUpJSdGWLVv0559/6sUXX9TBgwcVGhqqrVu3qlatWtmuOykpSb6+vjryx5/y8cn6WgEgN7gWstzZahRARZq+nN8lwOJMWopSfpyoxMTEG/7dtNRvvQoVKmjLli0qV66cHn30UZUvX149evRQixYttGnTJvn7X/747Ndee00HDx5U+fLl//ZU1rW6deumGTNmaObMmapevboiIiIUGxur0NC/vy4EAADkD0vN6NyumNHBrcKMDm4FZnSQ1/61MzoAAABXI+gAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLIugAAADLKpTfBUAyxkiSzp5NyudKYHWuhXhvg7xn0lLyuwRYnEm/fIxd+fv5dwg6BcDZs2clSVXCgvO5EgAAbh9nz56Vr6/v3/axmezEIeSpjIwMHTt2TN7e3rLZbPldzm0hKSlJZcqU0ZEjR+Tj45Pf5cCiOM5wK3Cc5ZwxRmfPnlXJkiXl5PT3M9XM6BQATk5OKl26dH6XcVvy8fHhFwPyHMcZbgWOs5y50UzOFZywBwAAlkXQAQAAlkXQwW3Jzc1Nw4cPl5ubW36XAgvjOMOtwHGWt7gYGQAAWBYzOgAAwLIIOgAAwLIIOgAAwLIIOgBwk2w2m5YsWZLfZeA2ExsbKz8/v/wuw/IIOshz0dHRstlsstlscnV1VVhYmF577TWlpaXld2m4DUVHR6tt27b5su8RI0aoVq1amdqPHz+u+++//9YXhALhyJEj6tKli0qWLClXV1cFBwerT58+io+Pt/cJCQnR+PHj86/IfzGCDm6J++67T8ePH9eePXv00ksvacSIEXrnnXdyvJ309HRlZGTkQYXAPxcYGMitwf9S+/fvV926dbVnzx7Nnz9fe/fu1ZQpU7RmzRo1atRIZ86cueU1paam3vJ9FmQEHdwSbm5uCgwMVHBwsHr27KmWLVtq6dKlSklJUf/+/VWqVCl5enqqQYMGWrdunX29K1O7S5cuVZUqVeTm5qbDhw9r3bp1ql+/vjw9PeXn56cmTZro0KFD9vUmT56s8uXLy9XVVZUqVdKcOXMc6rHZbJoxY4batWunwoULq0KFClq6dOmtejmQR9avX6/69evLzc1NQUFBGjRokMPMYUZGht5++22FhYXJzc1NZcuW1RtvvGFfPnDgQFWsWFGFCxdWuXLlNHToUPsfjdjYWMXExGj79u32GcrY2FhJmU9d7dy5U3fddZc8PDwUEBCgHj16KDk52b78yqzUmDFjFBQUpICAAD333HP8gboNPffcc3J1ddXKlSsVERGhsmXL6v7779fq1at19OhRvfrqq2revLkOHTqkfv362Y+dq3355ZcKDw+Xl5eX/U3h1WbMmKHw8HC5u7urcuXKmjRpkn3ZwYMHZbPZtHDhQkVERMjd3V1z5869JWO/bRggj0VFRZmHHnrIoa1NmzbmjjvuMN26dTONGzc2X3/9tdm7d6955513jJubm/ntt9+MMcbMnDnTuLi4mMaNG5sNGzaYXbt2mcTEROPr62v69+9v9u7da3799VcTGxtrDh06ZIwxZtGiRcbFxcV88MEHZvfu3Wbs2LHG2dnZfPXVV/b9SzKlS5c28+bNM3v27DG9e/c2Xl5eJj4+/pa9LvhnsjqejDHm999/N4ULFza9evUycXFxZvHixaZo0aJm+PDh9j4vv/yyKVKkiImNjTV79+4133zzjZk+fbp9+ciRI82GDRvMgQMHzNKlS02JEiXMW2+9ZYwx5vz58+all14yVatWNcePHzfHjx8358+fN8ZcPp4WL15sjDEmOTnZBAUFmfbt25udO3eaNWvWmNDQUBMVFeUwBh8fH/Pss8+auLg4s2zZMlO4cGEzbdq0XH+9kHfi4+ONzWYzo0aNynJ59+7dTZEiRczp06dN6dKlzWuvvWY/doz56/dby5YtzebNm82PP/5owsPDzRNPPGHfxkcffWSCgoLMp59+avbv328+/fRT4+/vb2JjY40xxhw4cMBIMiEhIfY+x44dy/vB30YIOshzV/9hysjIMKtWrTJubm4mOjraODs7m6NHjzr0v/vuu83gwYONMZd/EUgy27Ztsy+Pj483ksy6deuy3F/jxo1N9+7dHdoeeeQR06pVK/tzSWbIkCH258nJyUaS+fzzz29qrMh71ws6r7zyiqlUqZLJyMiwt33wwQfGy8vLpKenm6SkJOPm5uYQbG7knXfeMXXq1LE/Hz58uKlZs2amflcHnWnTppkiRYqY5ORk+/IVK1YYJycnc+LECfsYgoODTVpamr3PI488Yh577LFs14b899133zn87K81btw4I8n88ccfJjg42Lz77rsOy6/8ftu7d6+97YMPPjAlSpSwPy9fvryZN2+ew3ojR440jRo1Msb8FXTGjx+fO4OyIL69HLfE8uXL5eXlpdTUVGVkZOiJJ57Qww8/rNjYWFWsWNGhb0pKigICAuzPXV1dVaNGDftzf39/RUdHKzIyUvfcc49atmypRx99VEFBQZKkuLg49ejRw2GbTZo00YQJExzart6mp6enfHx8dPLkyVwbM26tuLg4NWrUyOG0QJMmTZScnKzff/9dJ06cUEpKiu6+++7rbmPhwoWaOHGi9u3bp+TkZKWlpeX426Tj4uJUs2ZNeXp6OtSRkZGh3bt3q0SJEpKkqlWrytnZ2d4nKChIO3fuzNG+UDCYm/iCgcKFC6t8+fL250FBQfbfQ+fOndO+ffvUtWtXde/e3d4nLS0t0zd3161b9x/XYHUEHdwSLVq00OTJk+Xq6qqSJUuqUKFCWrhwoZydnfXjjz86/MKXJC8vL/t/e3h4ZDqnPXPmTPXu3VtffPGFFi5cqCFDhmjVqlVq2LBhtmtycXFxeG6z2bjQ2cI8PDz+dvmmTZvUqVMnxcTEKDIyUr6+vlqwYIHGjh2bJ/Vw/N3+wsLCZLPZFBcXp3bt2mVaHhcXpyJFiqhYsWLX3UZWx8GV4HTluq7p06erQYMGDv2u/Z15dbCGIy5Gxi3h6empsLAwlS1bVoUKXc7XtWvXVnp6uk6ePKmwsDCHR2Bg4A23Wbt2bQ0ePFgbN25UtWrVNG/ePElSeHi4NmzY4NB3w4YNqlKlSu4PDAVGeHi4Nm3a5PDuesOGDfL29lbp0qVVoUIFeXh4aM2aNVmuv3HjRgUHB+vVV19V3bp1VaFCBYcL3KXLs4vp6ek3rGP79u06d+6cQx1OTk6qVKnSTYwQBU1AQIDuueceTZo0SRcuXHBYduLECc2dO1ePPfaY/aM1bnTsXKtEiRIqWbKk9u/fn+l3ZGhoaG4OxdIIOsg3FStWVKdOnfTUU09p0aJFOnDggH744QeNHj1aK1asuO56Bw4c0ODBg7Vp0yYdOnRIK1eu1J49exQeHi5JGjBggGJjYzV58mTt2bNH48aN06JFi9S/f/9bNTTkscTERG3bts3h0aNHDx05ckQvvPCCdu3apf/9738aPny4XnzxRTk5Ocnd3V0DBw7Uyy+/rNmzZ2vfvn367rvv9J///EeSVKFCBR0+fFgLFizQvn37NHHiRC1evNhhvyEhITpw4IC2bdum06dPKyUlJVNtnTp1kru7u6KiovTzzz9r7dq1euGFF/Tkk0/aT1vBOt5//32lpKQoMjJSX3/9tY4cOaIvvvhC99xzj0qVKmW/qy8kJERff/21jh49qtOnT2d7+zExMRo9erQmTpyo3377TTt37tTMmTM1bty4vBqS9eTzNUL4F7jexaPGGHPp0iUzbNgwExISYlxcXExQUJBp166d2bFjhzHm8sV6vr6+DuucOHHCtG3b1gQFBRlXV1cTHBxshg0bZtLT0+19Jk2aZMqVK2dcXFxMxYoVzezZsx22oSwuIPT19TUzZ8682eEij0VFRRlJmR5du3Y169atM/Xq1TOurq4mMDDQDBw40KSmptrXTU9PN6+//roJDg42Li4upmzZsg53zAwYMMAEBAQYLy8v89hjj5l3333X4fi7ePGi6dChg/Hz8zOS7MfLtcfTjh07TIsWLYy7u7vx9/c33bt3N2fPnnUYw7X/T/Tp08dERETk5kuFW+TgwYMmKirKlChRwri4uJgyZcqYF154wZw+fdreZ9OmTaZGjRrGzc3NXPnTm9Xvt8WLF5tr/zTPnTvX1KpVy7i6upoiRYqYO++80yxatMgY89fFyFu3bs3TMd7ObMbcxFVUAAAABRinrgAAgGURdAAAgGURdAAAgGURdAAAgGURdAAAgGURdAAAgGURdAAAgGURdAAAgGURdADc1qKjo9W2bVv78+bNm6tv3763vI5169bJZrMpISHhun1sNpuWLFmS7W2OGDFCtWrVuqm6Dh48KJvNpm3btt3UdoDbFUEHQK6Ljo6WzWazf5lhWFiYXnvtNaWlpeX5vhctWqSRI0dmq292wgmA21uh/C4AgDXdd999mjlzplJSUvTZZ5/pueeek4uLiwYPHpyp76VLl+Tq6por+/X398+V7QCwBmZ0AOQJNzc3BQYGKjg4WD179lTLli21dOlSSX+dbnrjjTdUsmRJVapUSZJ05MgRPfroo/Lz85O/v78eeughHTx40L7N9PR0vfjii/Lz81NAQIBefvllXft1fdeeukpJSdHAgQNVpkwZubm5KSwsTP/5z3908OBBtWjRQpJUpEgR2Ww2RUdHS5IyMjI0evRohYaGysPDQzVr1tQnn3zisJ/PPvtMFStWlIeHh1q0aOFQZ3YNHDhQFStWVOHChVWuXDkNHTpUqampmfpNnTpVZcqUUeHChfXoo48qMTHRYfmMGTMUHh4ud3d3Va5cWZMmTcpxLYBVEXQA3BIeHh66dOmS/fmaNWu0e/durVq1SsuXL1dqaqoiIyPl7e2tb775Rhs2bJCXl5fuu+8++3pjx45VbGysPvzwQ3377bc6c+aMFi9e/Lf7feqppzR//nxNnDhRcXFxmjp1qry8vFSmTBl9+umnkqTdu3fr+PHjmjBhgiRp9OjRmj17tqZMmaJffvlF/fr1U+fOnbV+/XpJlwNZ+/bt9eCDD2rbtm3q1q2bBg0alOPXxNvbW7Gxsfr11181YcIETZ8+Xe+++65Dn7179+rjjz/WsmXL9MUXX2jr1q3q1auXffncuXM1bNgwvfHGG4qLi9OoUaM0dOhQzZo1K8f1AJaUz9+eDsCCoqKizEMPPWSMMSYjI8OsWrXKuLm5mf79+9uXlyhRwqSkpNjXmTNnjqlUqZLJyMiwt6WkpBgPDw/z5ZdfGmOMCQoKMm+//bZ9eWpqqildurR9X8YYExERYfr06WOMMWb37t1Gklm1alWWda5du9ZIMn/++ae97eLFi6Zw4cJm48aNDn27du1qOnbsaIwxZvDgwaZKlSoOywcOHJhpW9eSZBYvXnzd5e+8846pU6eO/fnw4cONs7Oz+f333+1tn3/+uXFycjLHjx83xhhTvnx5M2/ePIftjBw50jRq1MgYY8yBAweMJLN169br7hewMq7RAZAnli9fLi8vL6WmpiojI0NPPPGERowYYV9evXp1h+tytm/frr1798rb29thOxcvXtS+ffuUmJio48ePq0GDBvZlhQoVUt26dTOdvrpi27ZtcnZ2VkRERLbr3rt3r86fP6977rnHof3SpUuqXbu2JCkuLs6hDklq1KhRtvdxxcKFCzVx4kTt27dPycnJSktLk4+Pj0OfsmXLqlSpUg77ycjI0O7du+Xt7a19+/apa9eu6t69u71PWlqafH19c1wPYEUEHQB5okWLFpo8ebJcXV1VsmRJFSrk+OvG09PT4XlycrLq1KmjuXPnZtpWsWLF/lENHh4eOV4nOTlZkrRixQqHgCFdvu4ot2zatEmdOnVSTEyMIiMj5evrqwULFmjs2LE5rnX69OmZgpezs3Ou1Qrczgg6APKEp6enwsLCst3/jjvu0MKFC1W8ePFMsxpXBAUF6fvvv9edd94p6fLMxY8//qg77rgjy/7Vq1dXRkaG1q9fr5YtW2ZafmVGKT093d5WpUoVubm56fDhw9edCQoPD7dfWH3Fd999d+NBXmXjxo0KDg7Wq6++am87dOhQpn6HDx/WsWPHVLJkSft+nJycVKlSJZUoUUIlS5bU/v371alTpxztH/i34GJkAAVCp06dVLRoUT300EP65ptvdODAAa1bt069e/fW77//Lknq06eP3nzzTS1ZskS7du1Sr169/vYzcEJCQhQVFaUuXbpoyZIl9m1+/PHHkqTg4GDZbDYtX75cp06dUnJysry9vdW/f3/169dPs2bN0r59+/TTTz/pvffes1/g++yzz2rPnj0aMGCAdu/erXnz5ik2NjZH461QoYIOHz6sBQsWaN++fZo4cWKWF1a7u7srKipK27dv1zfffKPevXvr0UcfVWBgoCQpJiZGo0eP1sSJE/Xbb79p586dmjlzpsaNG5ejegCrIugAKBAKFy6sr7/+WmXLllX79u0VHh6url276uLFi/YZnpdeeklPPvmkoqKi1KhRI3l7e6tdu3Z/u93Jkyfr4YcfVq9evVS5cmV1795d586dkySVKlVKMTExGjRokEqUKKHnn39ekjRy5EgNHTpUo0ePVnh4uO677z6tWLFCoaGhki5fN/Ppp59qyZIlqlmzpqZMmaJRo0blaLxt2rRRv3799Pzzz6tWrVrauHGjhg4dmqlfWFiY2rdvr1atWunee+9VjRo1HG4f79atm2bMmKGZM2eqevXqioiIUGxsrL1W4N/OZq53FR8AAMBtjhkdAABgWQQdAABgWQQdAABgWQQdAABgWQQdAABgWQQdAABgWQQdAABgWQQdAABgWQQdAABgWQQdAABgWQQdAABgWf8HosUbw6/GSxgAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "\n",
    "labels = ['Person', 'Location', 'Other']\n",
    "\n",
    "def plot_confusion_matrix(y_preds, y_true, labels):\n",
    "    cm = confusion_matrix(y_true, y_preds, normalize=\"true\")\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot(cmap=\"Blues\", values_format=\".2f\", ax=ax, colorbar=False)\n",
    "    plt.title(\"Normalized confusion matrix\")\n",
    "    plt.show()\n",
    "\n",
    "y_preds = np.argmax(preds_output.predictions, axis=1)\n",
    "y_valid = np.array(segments_encoded[\"test\"][\"label\"])\n",
    "\n",
    "plot_confusion_matrix(y_preds, y_valid, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_ed1 = np.argmax(preds_output_ed1.predictions, axis=1)\n",
    "\n",
    "for entry, label in zip(segments_ed1_list, y_preds_ed1):\n",
    "    article = entry['article']\n",
    "    \n",
    "    segments_ed1[article][0]['class'] = idx2label[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_json('segments', segments_ed1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_preds_ed2 = np.argmax(preds_output_ed2.predictions, axis=1)\n",
    "\n",
    "for entry, label in zip(segments_ed2_list, y_preds_ed2):\n",
    "    article = entry['article']\n",
    "    \n",
    "    segments_ed2[article][0]['class'] = idx2label[label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_json('segments', segments_ed2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "\n",
    "client = QdrantClient(\":memory:\")\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained('KB/bert-base-swedish-cased')\n",
    "model = AutoModel.from_pretrained('KB/bert-base-swedish-cased')\n",
    "\n",
    "# Function to generate embeddings for a single batch of data\n",
    "def generate_embeddings(batch, idx = 'text'):\n",
    "    inputs = tokenize(batch, idx)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        # Use the mean of the last hidden state as the embedding\n",
    "        embeddings = outputs.last_hidden_state.mean(dim=1).squeeze().numpy()\n",
    "    return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kalls\\AppData\\Local\\Temp\\ipykernel_5560\\3397181592.py:1: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
      "  client.recreate_collection(\n",
      "C:\\Users\\kalls\\AppData\\Local\\Temp\\ipykernel_5560\\3397181592.py:9: DeprecationWarning: `recreate_collection` method is deprecated and will be removed in the future. Use `collection_exists` to check collection existence and `create_collection` instead.\n",
      "  client.recreate_collection(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.recreate_collection(\n",
    "    collection_name=\"edition_1\",\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=768,  # Vector size is defined by used model\n",
    "        distance=models.Distance.COSINE,\n",
    "    ),\n",
    ")\n",
    "\n",
    "client.recreate_collection(\n",
    "    collection_name=\"edition_1\",\n",
    "    vectors_config=models.VectorParams(\n",
    "        size=768,  # Vector size is defined by used model\n",
    "        distance=models.Distance.COSINE,\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.upload_points(\n",
    "    collection_name=\"edition_1\",\n",
    "    points=[\n",
    "        models.PointStruct(\n",
    "            id=idx, vector=generate_embeddings(entry).tolist(), payload=entry\n",
    "        )\n",
    "        for idx, entry in enumerate(segments_ed1_list)\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'SequenceClassifierOutput' object has no attribute 'last_hidden_state'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[183], line 10\u001b[0m\n\u001b[0;32m      4\u001b[0m maximum \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(segments_ed2_list)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, entry \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(segments_ed2_list):\n\u001b[0;32m      8\u001b[0m     hits \u001b[38;5;241m=\u001b[39m client\u001b[38;5;241m.\u001b[39mquery_points(\n\u001b[0;32m      9\u001b[0m         collection_name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medition_1\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m---> 10\u001b[0m         query\u001b[38;5;241m=\u001b[39m\u001b[43mgenerate_embeddings\u001b[49m\u001b[43m(\u001b[49m\u001b[43mentry\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtolist(),\n\u001b[0;32m     11\u001b[0m         limit\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[0;32m     12\u001b[0m     )\u001b[38;5;241m.\u001b[39mpoints\n\u001b[0;32m     15\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hit \u001b[38;5;129;01min\u001b[39;00m hits:\n\u001b[0;32m     16\u001b[0m         \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(segments_ed2_dataset)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: ed2 \u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mentry[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhead\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m was matched against ed1 \u001b[39m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mhit\u001b[38;5;241m.\u001b[39mpayload[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhead\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\'\u001b[39;00m\u001b[38;5;124m with a score: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhit\u001b[38;5;241m.\u001b[39mscore\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[182], line 11\u001b[0m, in \u001b[0;36mgenerate_embeddings\u001b[1;34m(batch, idx)\u001b[0m\n\u001b[0;32m      9\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# Use the mean of the last hidden state as the embedding\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m     embeddings \u001b[38;5;241m=\u001b[39m \u001b[43moutputs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlast_hidden_state\u001b[49m\u001b[38;5;241m.\u001b[39mmean(dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39msqueeze()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m embeddings\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'SequenceClassifierOutput' object has no attribute 'last_hidden_state'"
     ]
    }
   ],
   "source": [
    "import keyboard\n",
    "\n",
    "correct = 0\n",
    "maximum = len(segments_ed2_list)\n",
    "\n",
    "for i, entry in enumerate(segments_ed2_list):\n",
    "    \n",
    "    hits = client.query_points(\n",
    "        collection_name=\"edition_1\",\n",
    "        query=generate_embeddings(entry).tolist(),\n",
    "        limit=1,\n",
    "    ).points\n",
    "    \n",
    "    \n",
    "    for hit in hits:\n",
    "        print(f\"{i}/{len(segments_ed2_dataset)}: ed2 \\'{entry['head']}\\' was matched against ed1 \\'{hit.payload['head']}\\' with a score: {hit.score}\")\n",
    "        \n",
    "    print('Press 1 if this is correct and 2 otherwise:\\n')\n",
    "    \n",
    "    while(True):\n",
    "        key_press = keyboard.read_key()\n",
    "\n",
    "        if key_press in {'1', '2'}:\n",
    "            correct += key_press == '1'\n",
    "            break\n",
    "    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.58"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct / maximum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "seg_ed1 = load_json('segments', 1, range(1, 1001))\n",
    "seg_ed2 = load_json('segments', 2, range(1, 1001))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "save_json('segments_small', seg_ed1, 1)\n",
    "save_json('segments_small', seg_ed2, 2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
